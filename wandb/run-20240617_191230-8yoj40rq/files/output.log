Disabling AUROC metric.
	Because dataset has 0 =/= 1 categorical target columns.
Loaded metadata for fixed test set. n_cv_splits set to 1.
Fixed test set provided. n_cv_splits set to 1.
Percentage of each group: Train 0.18 | Val 0.03 | Test 0.80
train val test split:  [   0  224  256 1256]
len missing matrix 1256
metadata {'N': 1256, 'D': 6, 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'cat_target_cols': [], 'num_target_cols': [2], 'input_feature_dims': [2, 2, 2, 2, 2, 2], 'fixed_test_set_index': 256, 'auroc_setting': False}
CV Index: 0
Train-test Split 1/1
Building NPT.
All features are either categorical or numerical. Not going to bother doing feature type embeddings.
Using feature type embedding (unique embedding for categorical and numerical features).
Using feature index embedding (unique embedding for each column).
Clipping gradients to value 1.0.
Model has 31576838 parameters,batch size -1.
Initialized "lookahead_lamb" optimizer.
Warming up for 70000.0/100000.0 steps.
Initialized "flat_and_anneal" learning rate scheduler.
Initialized "cosine" augmentation/label tradeoff annealer. Annealing to minimum value in 100000 steps.
Disabled AUROC in loss module.
batch dataset | train.py --------------- {'train_mask_matrix': tensor([[False, False, False, False, False, False],
        [False, False,  True, False, False, False],
        [False, False,  True, False, False, False],
        ...,
        [False, False, False, False, False, False],
        [False, False, False, False, False, False],
        [False, False, False, False, False, False]]), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[ 0.2597,  0.0000],
        [ 0.9760,  0.0000],
        [-1.6595,  0.0000],
        ...,
        [-1.1189,  0.0000],
        [-0.0106,  0.0000],
        [ 1.4626,  0.0000]]), tensor([[ 1.8207,  0.0000],
        [-1.2226,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [-1.0689,  0.0000],
        [-1.0074,  0.0000],
        [-0.3004,  0.0000]]), tensor([[ 0.0000,  1.0000],
        [-1.4049,  0.0000],
        [ 0.1436,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]])], 'masked_tensors': [tensor([[ 0.2597,  0.0000],
        [ 0.9760,  0.0000],
        [-1.6595,  0.0000],
        ...,
        [-1.1189,  0.0000],
        [-0.0106,  0.0000],
        [ 1.4626,  0.0000]]), tensor([[ 1.8207,  0.0000],
        [-1.2226,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [-1.0689,  0.0000],
        [-1.0074,  0.0000],
        [-0.3004,  0.0000]]), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 1.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 1.],
        [0., 0.]]), tensor([[0., 1.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]])], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7124006452866083, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[False, False, False, False,  True,  True],
        [False, False, False, False, False, False],
        [False, False, False, False, False, False],
        ...,
        [False, False, False, False, False, False],
        [False, False, False, False,  True, False],
        [False, False, False, False, False, False]])}
batch dataset | train.py --------------- {'train_mask_matrix': tensor([[False, False, False, False, False, False],
        [False, False, False, False, False, False],
        [False, False,  True, False, False, False],
        ...,
        [False, False, False, False, False, False],
        [False, False, False, False, False, False],
        [False, False, False, False, False, False]]), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[ 0.2056,  0.0000],
        [ 0.9760,  0.0000],
        [-0.6864,  0.0000],
        ...,
        [-1.3351,  0.0000],
        [-1.7136,  0.0000],
        [-1.6054,  0.0000]]), tensor([[-0.5771,  0.0000],
        [-0.8537,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [-0.1467,  0.0000],
        [ 0.0685,  0.0000],
        [ 1.7285,  0.0000]]), tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [1.3046, 0.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]])], 'masked_tensors': [tensor([[ 0.2056,  0.0000],
        [ 0.0000,  1.0000],
        [-0.6864,  0.0000],
        ...,
        [-1.3351,  0.0000],
        [-1.7136,  0.0000],
        [-1.6054,  0.0000]]), tensor([[-0.5771,  0.0000],
        [-0.8537,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [-0.1467,  0.0000],
        [ 0.0685,  0.0000],
        [ 1.7285,  0.0000]]), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 1.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 1.],
        [0., 1.]]), tensor([[0., 1.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 1.],
        [0., 0.],
        [0., 0.]])], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7124006452866083, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[False, False, False, False,  True,  True],
        [ True, False, False, False, False, False],
        [False, False, False, False, False, False],
        ...,
        [False, False, False, False, False,  True],
        [False, False, False, False,  True, False],
        [False, False, False, False,  True, False]])}
batch dataset | train.py --------------- {'train_mask_matrix': tensor([[False, False, False, False, False, False],
        [False, False, False, False, False, False],
        [False, False, False, False, False, False],
        ...,
        [False, False, False, False, False, False],
        [False, False, False, False, False, False],
        [False, False, False, False, False, False]]), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[ 0.4489,  0.0000],
        [ 1.7194,  0.0000],
        [-1.0378,  0.0000],
        ...,
        [ 1.3815,  0.0000],
        [ 1.3274,  0.0000],
        [ 1.2058,  0.0000]]), tensor([[ 0.0685,  0.0000],
        [-0.1774,  0.0000],
        [ 1.1137,  0.0000],
        ...,
        [ 1.6977,  0.0000],
        [ 0.8370,  0.0000],
        [ 0.3451,  0.0000]]), tensor([[ 0.0000,  1.0000],
        [-0.0627,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]])], 'masked_tensors': [tensor([[0.4489, 0.0000],
        [1.7194, 0.0000],
        [0.0000, 1.0000],
        ...,
        [1.3815, 0.0000],
        [1.3274, 0.0000],
        [1.2058, 0.0000]]), tensor([[ 0.0685,  0.0000],
        [-0.1774,  0.0000],
        [ 1.1137,  0.0000],
        ...,
        [ 1.6977,  0.0000],
        [ 0.8370,  0.0000],
        [ 0.0000,  1.0000]]), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]]), tensor([[0., 1.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 1.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 1.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 1.],
        [0., 0.]])], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7124006452866083, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[False, False, False,  True, False, False],
        [False, False, False, False, False, False],
        [ True, False, False, False, False,  True],
        ...,
        [False, False, False, False, False, False],
        [False, False, False, False,  True,  True],
        [False,  True, False,  True, False, False]])}
batch dataset | train.py --------------- {'train_mask_matrix': tensor([[False, False, False, False, False, False],
        [False, False,  True, False, False, False],
        [False, False, False, False, False, False],
        ...,
        [False, False, False, False, False, False],
        [False, False, False, False, False, False],
        [False, False, False, False, False, False]]), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[ 0.1110,  0.0000],
        [ 0.2597,  0.0000],
        [-1.5649,  0.0000],
        ...,
        [-1.4027,  0.0000],
        [ 1.0571,  0.0000],
        [ 0.4219,  0.0000]]), tensor([[-0.7308,  0.0000],
        [-1.2226,  0.0000],
        [ 0.0685,  0.0000],
        ...,
        [ 0.9600,  0.0000],
        [-1.2226,  0.0000],
        [ 0.9907,  0.0000]]), tensor([[ 0.0000,  1.0000],
        [-0.6593,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [-1.3499,  0.0000],
        [ 0.0000,  1.0000]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]])], 'masked_tensors': [tensor([[ 0.1110,  0.0000],
        [ 0.2597,  0.0000],
        [-1.5649,  0.0000],
        ...,
        [-1.4027,  0.0000],
        [ 1.0571,  0.0000],
        [ 0.4219,  0.0000]]), tensor([[-0.7308,  0.0000],
        [-1.2226,  0.0000],
        [ 0.0685,  0.0000],
        ...,
        [ 0.9600,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.9907,  0.0000]]), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 1.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 1.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]])], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7124006452866083, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[False, False, False, False, False, False],
        [False, False, False, False, False, False],
        [False, False, False, False,  True, False],
        ...,
        [False, False, False, False, False, False],
        [False,  True, False, False, False, False],
        [False, False, False,  True,  True, False]])}
batch dataset | train.py --------------- {'train_mask_matrix': tensor([[False, False, False, False, False, False],
        [False, False, False, False, False, False],
        [False, False, False, False, False, False],
        ...,
        [False, False, False, False, False, False],
        [False, False, False, False, False, False],
        [False, False, False, False, False, False]]), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[ 0.3678,  0.0000],
        [-1.2675,  0.0000],
        [ 0.6787,  0.0000],
        ...,
        [-0.9702,  0.0000],
        [ 0.2056,  0.0000],
        [-0.9432,  0.0000]]), tensor([[0.4989, 0.0000],
        [0.1607, 0.0000],
        [0.3759, 0.0000],
        ...,
        [1.0214, 0.0000],
        [0.8063, 0.0000],
        [0.4374, 0.0000]]), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]])], 'masked_tensors': [tensor([[ 0.3678,  0.0000],
        [-1.2675,  0.0000],
        [ 0.6787,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.2056,  0.0000],
        [-0.9432,  0.0000]]), tensor([[0.4989, 0.0000],
        [0.1607, 0.0000],
        [0.3759, 0.0000],
        ...,
        [1.0214, 0.0000],
        [0.8063, 0.0000],
        [0.0000, 1.0000]]), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]]), tensor([[0., 1.],
        [0., 0.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[ 0.0000,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  0.0000],
        ...,
        [-0.8320,  0.0000],
        [-1.5130,  0.0000],
        [ 0.0000,  0.0000]]), tensor([[0., 1.],
        [0., 0.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 1.],
        [0., 0.]])], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7124006452866083, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[False, False, False,  True, False,  True],
        [False, False, False, False,  True, False],
        [False, False, False,  True, False,  True],
        ...,
        [ True, False, False, False,  True, False],
        [False, False, False, False,  True,  True],
        [False,  True, False, False, False, False]])}
batch dataset | train.py --------------- {'val_mask_matrix': tensor([[False, False, False, False, False, False],
        [False, False, False, False, False, False],
        [False, False, False, False, False, False],
        ...,
        [False, False, False, False, False, False],
        [False, False, False, False, False, False],
        [False, False, False, False, False, False]]), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[-1.5919,  0.0000],
        [-0.6323,  0.0000],
        [-1.5784,  0.0000],
        ...,
        [-1.4432,  0.0000],
        [-0.9297,  0.0000],
        [ 1.1652,  0.0000]]), tensor([[ 0.0377,  0.0000],
        [-1.2226,  0.0000],
        [ 1.1751,  0.0000],
        ...,
        [ 1.7592,  0.0000],
        [ 1.4826,  0.0000],
        [-0.7615,  0.0000]]), tensor([[0.0000, 1.0000],
        [1.2551, 0.0000],
        [0.0000, 1.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]])], 'masked_tensors': [tensor([[-1.5919,  0.0000],
        [-0.6323,  0.0000],
        [-1.5784,  0.0000],
        ...,
        [-1.4432,  0.0000],
        [-0.9297,  0.0000],
        [ 1.1652,  0.0000]]), tensor([[ 0.0377,  0.0000],
        [-1.2226,  0.0000],
        [ 1.1751,  0.0000],
        ...,
        [ 1.7592,  0.0000],
        [ 1.4826,  0.0000],
        [-0.7615,  0.0000]]), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]]), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]])], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7124006452866083, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': None}
/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/Users/devu/PycharmProjects/non-parametric-transformers/npt/mask.py:108: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403207619/work/torch/csrc/utils/tensor_new.cpp:620.)
  mask = torch.sparse.FloatTensor(
Traceback (most recent call last):
  File "run.py", line 204, in <module>
    main(args)
  File "run.py", line 23, in main
    run_cv(args=args, wandb_args=wandb_args)
  File "run.py", line 117, in run_cv
    run_cv_splits(wandb_args, args, c, wandb_run)
  File "run.py", line 195, in run_cv_splits
    trainer.train_and_eval()
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 216, in train_and_eval
    if self.per_epoch_train_eval(epoch=epoch):
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 175, in per_epoch_train_eval
    early_stop = self.eval_model(
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 224, in eval_model
    val_loss = self.run_epoch(dataset_mode='val', **kwargs)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 448, in run_epoch
    loss_dict = self.loss.finalize_epoch_losses(eval_model)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/loss.py", line 334, in finalize_epoch_losses
    std_dict = self.finalize_losses(self.epoch_loss, eval_model)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/loss.py", line 373, in finalize_losses
    self.detach_all(raw_dict)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/loss.py", line 571, in detach_all
    for mode in raw_dict.keys():
AttributeError: 'NoneType' object has no attribute 'keys'
Traceback (most recent call last):
  File "run.py", line 204, in <module>
    main(args)
  File "run.py", line 23, in main
    run_cv(args=args, wandb_args=wandb_args)
  File "run.py", line 117, in run_cv
    run_cv_splits(wandb_args, args, c, wandb_run)
  File "run.py", line 195, in run_cv_splits
    trainer.train_and_eval()
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 216, in train_and_eval
    if self.per_epoch_train_eval(epoch=epoch):
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 175, in per_epoch_train_eval
    early_stop = self.eval_model(
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 224, in eval_model
    val_loss = self.run_epoch(dataset_mode='val', **kwargs)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 448, in run_epoch
    loss_dict = self.loss.finalize_epoch_losses(eval_model)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/loss.py", line 334, in finalize_epoch_losses
    std_dict = self.finalize_losses(self.epoch_loss, eval_model)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/loss.py", line 373, in finalize_losses
    self.detach_all(raw_dict)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/loss.py", line 571, in detach_all
    for mode in raw_dict.keys():
AttributeError: 'NoneType' object has no attribute 'keys'