CV Splits for this dataset are cached. Loading from file.
CV Index: 0
Train-test Split 1/5
c.exp_n_runs = 1. Stopping at 1 splits.
Building NPT.
Using feature type embedding (unique embedding for categorical and numerical features).
Using feature index embedding (unique embedding for each column).
Clipping gradients to value 1.0.
Model has 6557703968 parameters,batch size -1.
Initialized "lookahead_lamb" optimizer.
NPTModel(
  (enc): Sequential(
    (0): ReshapeToFlat()
    (1): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_k): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_v): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_mix_heads): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_res): Linear(in_features=7936, out_features=7936, bias=True)
        (ln0): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=7936, out_features=31744, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=31744, out_features=7936, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (2): ReshapeToNested()
    (3): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=256, out_features=256, bias=True)
        (fc_k): Linear(in_features=256, out_features=256, bias=True)
        (fc_v): Linear(in_features=256, out_features=256, bias=True)
        (fc_mix_heads): Linear(in_features=256, out_features=256, bias=True)
        (fc_res): Linear(in_features=256, out_features=256, bias=True)
        (ln0): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=1024, out_features=256, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (4): ReshapeToFlat()
    (5): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_k): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_v): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_mix_heads): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_res): Linear(in_features=7936, out_features=7936, bias=True)
        (ln0): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=7936, out_features=31744, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=31744, out_features=7936, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (6): ReshapeToNested()
    (7): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=256, out_features=256, bias=True)
        (fc_k): Linear(in_features=256, out_features=256, bias=True)
        (fc_v): Linear(in_features=256, out_features=256, bias=True)
        (fc_mix_heads): Linear(in_features=256, out_features=256, bias=True)
        (fc_res): Linear(in_features=256, out_features=256, bias=True)
        (ln0): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=1024, out_features=256, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (8): ReshapeToFlat()
    (9): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_k): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_v): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_mix_heads): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_res): Linear(in_features=7936, out_features=7936, bias=True)
        (ln0): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=7936, out_features=31744, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=31744, out_features=7936, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (10): ReshapeToNested()
    (11): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=256, out_features=256, bias=True)
        (fc_k): Linear(in_features=256, out_features=256, bias=True)
        (fc_v): Linear(in_features=256, out_features=256, bias=True)
        (fc_mix_heads): Linear(in_features=256, out_features=256, bias=True)
        (fc_res): Linear(in_features=256, out_features=256, bias=True)
        (ln0): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=1024, out_features=256, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (12): ReshapeToFlat()
    (13): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_k): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_v): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_mix_heads): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_res): Linear(in_features=7936, out_features=7936, bias=True)
        (ln0): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=7936, out_features=31744, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=31744, out_features=7936, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (14): ReshapeToNested()
    (15): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=256, out_features=256, bias=True)
        (fc_k): Linear(in_features=256, out_features=256, bias=True)
        (fc_v): Linear(in_features=256, out_features=256, bias=True)
        (fc_mix_heads): Linear(in_features=256, out_features=256, bias=True)
        (fc_res): Linear(in_features=256, out_features=256, bias=True)
        (ln0): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=1024, out_features=256, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (16): ReshapeToFlat()
    (17): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_k): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_v): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_mix_heads): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_res): Linear(in_features=7936, out_features=7936, bias=True)
        (ln0): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=7936, out_features=31744, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=31744, out_features=7936, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (18): ReshapeToNested()
    (19): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=256, out_features=256, bias=True)
        (fc_k): Linear(in_features=256, out_features=256, bias=True)
        (fc_v): Linear(in_features=256, out_features=256, bias=True)
        (fc_mix_heads): Linear(in_features=256, out_features=256, bias=True)
        (fc_res): Linear(in_features=256, out_features=256, bias=True)
        (ln0): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=1024, out_features=256, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (20): ReshapeToFlat()
    (21): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_k): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_v): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_mix_heads): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_res): Linear(in_features=7936, out_features=7936, bias=True)
        (ln0): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=7936, out_features=31744, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=31744, out_features=7936, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (22): ReshapeToNested()
    (23): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=256, out_features=256, bias=True)
        (fc_k): Linear(in_features=256, out_features=256, bias=True)
        (fc_v): Linear(in_features=256, out_features=256, bias=True)
        (fc_mix_heads): Linear(in_features=256, out_features=256, bias=True)
        (fc_res): Linear(in_features=256, out_features=256, bias=True)
        (ln0): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=1024, out_features=256, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (24): ReshapeToFlat()
    (25): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_k): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_v): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_mix_heads): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_res): Linear(in_features=7936, out_features=7936, bias=True)
        (ln0): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=7936, out_features=31744, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=31744, out_features=7936, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (26): ReshapeToNested()
    (27): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=256, out_features=256, bias=True)
        (fc_k): Linear(in_features=256, out_features=256, bias=True)
        (fc_v): Linear(in_features=256, out_features=256, bias=True)
        (fc_mix_heads): Linear(in_features=256, out_features=256, bias=True)
        (fc_res): Linear(in_features=256, out_features=256, bias=True)
        (ln0): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=1024, out_features=256, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (28): ReshapeToFlat()
    (29): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_k): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_v): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_mix_heads): Linear(in_features=7936, out_features=7936, bias=True)
        (fc_res): Linear(in_features=7936, out_features=7936, bias=True)
        (ln0): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((7936,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=7936, out_features=31744, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=31744, out_features=7936, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (30): ReshapeToNested()
    (31): MHSA(
      (mab): MAB(
        (fc_q): Linear(in_features=256, out_features=256, bias=True)
        (fc_k): Linear(in_features=256, out_features=256, bias=True)
        (fc_v): Linear(in_features=256, out_features=256, bias=True)
        (fc_mix_heads): Linear(in_features=256, out_features=256, bias=True)
        (fc_res): Linear(in_features=256, out_features=256, bias=True)
        (ln0): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (ln1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (hidden_dropout): Dropout(p=0.1, inplace=False)
        (att_scores_dropout): Dropout(p=0.1, inplace=False)
        (rff): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=1024, out_features=256, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (32): ReshapeToFlat()
    (33): ReshapeToNested()
  )
  (embedding_dropout): Dropout(p=0.1, inplace=False)
  (in_embedding): ModuleList(
    (0): Linear(in_features=3, out_features=256, bias=True)
    (1-30): 30 x Linear(in_features=2, out_features=256, bias=True)
  )
  (feature_type_embedding): Embedding(2, 256)
  (feature_index_embedding): Embedding(31, 256)
  (out_embedding): ModuleList(
    (0): Linear(in_features=256, out_features=2, bias=True)
    (1-30): 30 x Linear(in_features=256, out_features=1, bias=True)
  )
)
Warming up for 70000.0/100000.0 steps.
Initialized "flat_and_anneal" learning rate scheduler.
Initialized "cosine" augmentation/label tradeoff annealer. Annealing to minimum value in 100000 steps.
Using AUROC in loss module.
/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/Users/devu/PycharmProjects/non-parametric-transformers/npt/mask.py:108: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403207619/work/torch/csrc/utils/tensor_new.cpp:620.)
  mask = torch.sparse.FloatTensor(
Traceback (most recent call last):
  File "run.py", line 204, in <module>
    main(args)
  File "run.py", line 23, in main
    run_cv(args=args, wandb_args=wandb_args)
  File "run.py", line 117, in run_cv
    run_cv_splits(wandb_args, args, c, wandb_run)
  File "run.py", line 195, in run_cv_splits
    trainer.train_and_eval()
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 217, in train_and_eval
    if self.per_epoch_train_eval(epoch=epoch):
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 172, in per_epoch_train_eval
    train_loss = self.run_epoch(dataset_mode='train', epoch=epoch,
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 437, in run_epoch
    self.run_batch(
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 546, in run_batch
    self.forward_and_loss(**forward_kwargs)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 601, in forward_and_loss
    output = self.model(masked_tensors, **extra_args)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/model/npt.py", line 428, in forward
    X = self.enc(X)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/model/npt_modules.py", line 237, in forward
    return self.mab(X, X)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/model/npt_modules.py", line 137, in forward
    K = self.fc_k(Y)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt