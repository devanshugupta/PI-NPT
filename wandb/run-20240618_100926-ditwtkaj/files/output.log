/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/Users/devu/PycharmProjects/non-parametric-transformers/npt/mask.py:108: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403207619/work/torch/csrc/utils/tensor_new.cpp:620.)
  mask = torch.sparse.FloatTensor(
Loaded metadata for fixed test set. n_cv_splits set to 1.
CV Splits for this dataset are cached. Loading from file.
CV Index: 0
Train-test Split 1/1
Building NPT.
All features are either categorical or numerical. Not going to bother doing feature type embeddings.
Using feature type embedding (unique embedding for categorical and numerical features).
Using feature index embedding (unique embedding for each column).
Clipping gradients to value 1.0.
Model has 31576838 parameters,batch size -1.
Initialized "lookahead_lamb" optimizer.
Warming up for 70000.0/100000.0 steps.
Initialized "flat_and_anneal" learning rate scheduler.
Initialized "cosine" augmentation/label tradeoff annealer. Annealing to minimum value in 100000 steps.
Disabled AUROC in loss module.
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(185., grad_fn=<SumBackward0>)
col loss indices --------- 0 ---------- tensor([[  10],
        [  11],
        [  13],
        [  19],
        [  37],
        [  46],
        [  49],
        [  52],
        [  63],
        [  69],
        [  87],
        [  89],
        [  91],
        [  93],
        [ 102],
        [ 106],
        [ 125],
        [ 127],
        [ 135],
        [ 142],
        [ 148],
        [ 160],
        [ 163],
        [ 167],
        [ 193],
        [ 194],
        [ 201],
        [ 202],
        [ 205],
        [ 211],
        [ 215],
        [ 231],
        [ 236],
        [ 263],
        [ 264],
        [ 267],
        [ 280],
        [ 281],
        [ 284],
        [ 285],
        [ 293],
        [ 294],
        [ 296],
        [ 299],
        [ 303],
        [ 309],
        [ 315],
        [ 319],
        [ 323],
        [ 330],
        [ 333],
        [ 336],
        [ 337],
        [ 351],
        [ 368],
        [ 373],
        [ 376],
        [ 383],
        [ 389],
        [ 393],
        [ 398],
        [ 400],
        [ 404],
        [ 407],
        [ 413],
        [ 415],
        [ 422],
        [ 430],
        [ 436],
        [ 441],
        [ 442],
        [ 443],
        [ 449],
        [ 452],
        [ 475],
        [ 481],
        [ 491],
        [ 499],
        [ 503],
        [ 512],
        [ 517],
        [ 519],
        [ 536],
        [ 550],
        [ 552],
        [ 565],
        [ 567],
        [ 568],
        [ 569],
        [ 573],
        [ 574],
        [ 577],
        [ 587],
        [ 590],
        [ 599],
        [ 605],
        [ 609],
        [ 610],
        [ 617],
        [ 624],
        [ 642],
        [ 649],
        [ 662],
        [ 667],
        [ 668],
        [ 669],
        [ 679],
        [ 689],
        [ 703],
        [ 707],
        [ 711],
        [ 718],
        [ 723],
        [ 725],
        [ 739],
        [ 743],
        [ 751],
        [ 764],
        [ 781],
        [ 782],
        [ 792],
        [ 795],
        [ 799],
        [ 817],
        [ 828],
        [ 834],
        [ 835],
        [ 837],
        [ 862],
        [ 864],
        [ 865],
        [ 870],
        [ 890],
        [ 903],
        [ 905],
        [ 924],
        [ 938],
        [ 942],
        [ 969],
        [ 972],
        [ 977],
        [ 982],
        [ 987],
        [ 989],
        [ 990],
        [ 991],
        [ 993],
        [ 997],
        [1004],
        [1010],
        [1013],
        [1018],
        [1020],
        [1028],
        [1036],
        [1039],
        [1073],
        [1077],
        [1087],
        [1092],
        [1099],
        [1103],
        [1112],
        [1114],
        [1119],
        [1122],
        [1123],
        [1126],
        [1127],
        [1132],
        [1134],
        [1153],
        [1156],
        [1165],
        [1177],
        [1178],
        [1188],
        [1190],
        [1203],
        [1212],
        [1225],
        [1227],
        [1228],
        [1231],
        [1245]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0009, grad_fn=<MeanBackward0>)
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(181., grad_fn=<SumBackward0>)
col loss indices --------- 1 ---------- tensor([[   6],
        [   8],
        [  11],
        [  12],
        [  18],
        [  20],
        [  21],
        [  26],
        [  35],
        [  36],
        [  50],
        [  64],
        [  76],
        [  95],
        [  97],
        [  99],
        [ 102],
        [ 115],
        [ 117],
        [ 120],
        [ 128],
        [ 135],
        [ 139],
        [ 141],
        [ 142],
        [ 143],
        [ 147],
        [ 153],
        [ 157],
        [ 162],
        [ 171],
        [ 173],
        [ 199],
        [ 211],
        [ 212],
        [ 216],
        [ 231],
        [ 233],
        [ 235],
        [ 244],
        [ 252],
        [ 256],
        [ 264],
        [ 269],
        [ 279],
        [ 281],
        [ 300],
        [ 312],
        [ 321],
        [ 326],
        [ 331],
        [ 334],
        [ 341],
        [ 344],
        [ 345],
        [ 349],
        [ 357],
        [ 362],
        [ 377],
        [ 383],
        [ 385],
        [ 393],
        [ 395],
        [ 396],
        [ 406],
        [ 407],
        [ 412],
        [ 433],
        [ 436],
        [ 444],
        [ 450],
        [ 453],
        [ 487],
        [ 494],
        [ 495],
        [ 514],
        [ 529],
        [ 530],
        [ 531],
        [ 543],
        [ 551],
        [ 553],
        [ 561],
        [ 563],
        [ 565],
        [ 567],
        [ 570],
        [ 572],
        [ 577],
        [ 585],
        [ 586],
        [ 592],
        [ 606],
        [ 610],
        [ 621],
        [ 624],
        [ 626],
        [ 641],
        [ 644],
        [ 646],
        [ 649],
        [ 659],
        [ 660],
        [ 675],
        [ 678],
        [ 679],
        [ 682],
        [ 688],
        [ 720],
        [ 729],
        [ 733],
        [ 754],
        [ 757],
        [ 764],
        [ 769],
        [ 771],
        [ 792],
        [ 798],
        [ 802],
        [ 824],
        [ 837],
        [ 838],
        [ 848],
        [ 852],
        [ 853],
        [ 863],
        [ 866],
        [ 868],
        [ 876],
        [ 878],
        [ 892],
        [ 898],
        [ 907],
        [ 913],
        [ 916],
        [ 917],
        [ 927],
        [ 929],
        [ 930],
        [ 945],
        [ 952],
        [ 959],
        [ 963],
        [ 967],
        [ 978],
        [ 990],
        [ 992],
        [1011],
        [1014],
        [1015],
        [1017],
        [1037],
        [1038],
        [1039],
        [1074],
        [1077],
        [1088],
        [1093],
        [1114],
        [1121],
        [1131],
        [1135],
        [1136],
        [1137],
        [1142],
        [1145],
        [1160],
        [1164],
        [1167],
        [1174],
        [1175],
        [1178],
        [1183],
        [1199],
        [1224],
        [1226],
        [1228],
        [1234],
        [1240],
        [1241],
        [1242]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0004, grad_fn=<MeanBackward0>)
Mode ----------- label
target cols: ---------- [2]
number of predicted values: ---------- tensor(224., grad_fn=<SumBackward0>)
col loss indices --------- 2 ---------- tensor([[   1],
        [   2],
        [   3],
        [  12],
        [  22],
        [  29],
        [  39],
        [  43],
        [  47],
        [  56],
        [  57],
        [  63],
        [  64],
        [  67],
        [  69],
        [  71],
        [  94],
        [  95],
        [  97],
        [  98],
        [ 103],
        [ 112],
        [ 116],
        [ 120],
        [ 123],
        [ 132],
        [ 138],
        [ 151],
        [ 154],
        [ 155],
        [ 177],
        [ 179],
        [ 189],
        [ 195],
        [ 196],
        [ 210],
        [ 213],
        [ 221],
        [ 222],
        [ 230],
        [ 237],
        [ 238],
        [ 241],
        [ 244],
        [ 246],
        [ 247],
        [ 253],
        [ 269],
        [ 275],
        [ 285],
        [ 298],
        [ 299],
        [ 309],
        [ 312],
        [ 316],
        [ 341],
        [ 342],
        [ 345],
        [ 353],
        [ 354],
        [ 366],
        [ 367],
        [ 381],
        [ 382],
        [ 384],
        [ 385],
        [ 407],
        [ 408],
        [ 416],
        [ 418],
        [ 432],
        [ 435],
        [ 437],
        [ 439],
        [ 441],
        [ 442],
        [ 446],
        [ 470],
        [ 473],
        [ 477],
        [ 489],
        [ 492],
        [ 499],
        [ 511],
        [ 512],
        [ 514],
        [ 518],
        [ 524],
        [ 543],
        [ 544],
        [ 546],
        [ 553],
        [ 554],
        [ 556],
        [ 566],
        [ 569],
        [ 573],
        [ 574],
        [ 577],
        [ 581],
        [ 590],
        [ 594],
        [ 599],
        [ 622],
        [ 623],
        [ 624],
        [ 628],
        [ 638],
        [ 645],
        [ 647],
        [ 650],
        [ 652],
        [ 656],
        [ 657],
        [ 670],
        [ 671],
        [ 673],
        [ 676],
        [ 679],
        [ 684],
        [ 689],
        [ 690],
        [ 691],
        [ 695],
        [ 696],
        [ 698],
        [ 706],
        [ 722],
        [ 723],
        [ 728],
        [ 754],
        [ 760],
        [ 764],
        [ 772],
        [ 776],
        [ 777],
        [ 790],
        [ 796],
        [ 804],
        [ 805],
        [ 807],
        [ 811],
        [ 821],
        [ 822],
        [ 825],
        [ 827],
        [ 831],
        [ 834],
        [ 835],
        [ 841],
        [ 847],
        [ 857],
        [ 860],
        [ 864],
        [ 868],
        [ 872],
        [ 880],
        [ 884],
        [ 885],
        [ 886],
        [ 889],
        [ 902],
        [ 903],
        [ 908],
        [ 915],
        [ 923],
        [ 925],
        [ 939],
        [ 940],
        [ 949],
        [ 964],
        [ 965],
        [ 971],
        [ 972],
        [ 976],
        [ 981],
        [ 987],
        [ 989],
        [ 991],
        [ 992],
        [ 994],
        [ 995],
        [1010],
        [1017],
        [1032],
        [1038],
        [1042],
        [1045],
        [1046],
        [1048],
        [1050],
        [1062],
        [1071],
        [1077],
        [1079],
        [1082],
        [1088],
        [1089],
        [1096],
        [1098],
        [1099],
        [1127],
        [1134],
        [1147],
        [1155],
        [1156],
        [1158],
        [1171],
        [1172],
        [1176],
        [1178],
        [1190],
        [1191],
        [1200],
        [1201],
        [1205],
        [1210],
        [1214],
        [1216],
        [1224],
        [1233],
        [1243],
        [1246],
        [1250]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0006, grad_fn=<MeanBackward0>)
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(0., grad_fn=<SumBackward0>)
col loss indices --------- 2 ---------- tensor([], size=(0, 1), dtype=torch.int64)
Computing PINNs Loss:
Physics Loss:  tensor(0.0006, grad_fn=<MeanBackward0>)
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(201., grad_fn=<SumBackward0>)
col loss indices --------- 3 ---------- tensor([[   3],
        [   7],
        [  17],
        [  26],
        [  31],
        [  33],
        [  35],
        [  43],
        [  44],
        [  51],
        [  66],
        [  73],
        [  83],
        [  91],
        [  94],
        [  97],
        [ 128],
        [ 129],
        [ 136],
        [ 142],
        [ 147],
        [ 148],
        [ 165],
        [ 185],
        [ 186],
        [ 191],
        [ 196],
        [ 200],
        [ 203],
        [ 204],
        [ 205],
        [ 208],
        [ 211],
        [ 217],
        [ 228],
        [ 234],
        [ 239],
        [ 240],
        [ 248],
        [ 253],
        [ 255],
        [ 256],
        [ 257],
        [ 259],
        [ 264],
        [ 270],
        [ 282],
        [ 290],
        [ 301],
        [ 305],
        [ 312],
        [ 323],
        [ 334],
        [ 346],
        [ 347],
        [ 363],
        [ 366],
        [ 370],
        [ 372],
        [ 373],
        [ 374],
        [ 376],
        [ 379],
        [ 383],
        [ 390],
        [ 394],
        [ 399],
        [ 400],
        [ 417],
        [ 421],
        [ 422],
        [ 428],
        [ 430],
        [ 431],
        [ 445],
        [ 447],
        [ 457],
        [ 462],
        [ 463],
        [ 466],
        [ 471],
        [ 474],
        [ 479],
        [ 489],
        [ 491],
        [ 497],
        [ 498],
        [ 514],
        [ 516],
        [ 525],
        [ 529],
        [ 539],
        [ 542],
        [ 549],
        [ 555],
        [ 556],
        [ 559],
        [ 562],
        [ 576],
        [ 583],
        [ 596],
        [ 597],
        [ 602],
        [ 609],
        [ 611],
        [ 615],
        [ 618],
        [ 624],
        [ 628],
        [ 643],
        [ 661],
        [ 663],
        [ 666],
        [ 672],
        [ 678],
        [ 688],
        [ 695],
        [ 696],
        [ 701],
        [ 703],
        [ 705],
        [ 710],
        [ 713],
        [ 716],
        [ 723],
        [ 724],
        [ 732],
        [ 735],
        [ 748],
        [ 754],
        [ 762],
        [ 767],
        [ 770],
        [ 772],
        [ 785],
        [ 787],
        [ 788],
        [ 792],
        [ 796],
        [ 801],
        [ 805],
        [ 806],
        [ 815],
        [ 818],
        [ 831],
        [ 842],
        [ 857],
        [ 870],
        [ 873],
        [ 886],
        [ 889],
        [ 892],
        [ 893],
        [ 894],
        [ 898],
        [ 906],
        [ 911],
        [ 916],
        [ 920],
        [ 927],
        [ 928],
        [ 929],
        [ 951],
        [ 953],
        [ 968],
        [ 971],
        [ 972],
        [ 978],
        [ 990],
        [1002],
        [1005],
        [1006],
        [1030],
        [1033],
        [1039],
        [1047],
        [1061],
        [1063],
        [1076],
        [1079],
        [1086],
        [1094],
        [1123],
        [1127],
        [1133],
        [1137],
        [1139],
        [1141],
        [1142],
        [1144],
        [1173],
        [1184],
        [1193],
        [1197],
        [1200],
        [1207],
        [1223],
        [1227],
        [1236],
        [1238],
        [1248]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0005, grad_fn=<MeanBackward0>)
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(189., grad_fn=<SumBackward0>)
col loss indices --------- 4 ---------- tensor([[   0],
        [   4],
        [   6],
        [   9],
        [  14],
        [  18],
        [  19],
        [  33],
        [  46],
        [  52],
        [  61],
        [  63],
        [  65],
        [  70],
        [  77],
        [  78],
        [  81],
        [  90],
        [  93],
        [ 100],
        [ 102],
        [ 103],
        [ 106],
        [ 107],
        [ 108],
        [ 120],
        [ 124],
        [ 136],
        [ 137],
        [ 146],
        [ 148],
        [ 149],
        [ 152],
        [ 154],
        [ 164],
        [ 170],
        [ 171],
        [ 172],
        [ 175],
        [ 181],
        [ 203],
        [ 210],
        [ 212],
        [ 215],
        [ 220],
        [ 224],
        [ 225],
        [ 232],
        [ 233],
        [ 237],
        [ 238],
        [ 240],
        [ 250],
        [ 263],
        [ 274],
        [ 276],
        [ 287],
        [ 296],
        [ 306],
        [ 311],
        [ 313],
        [ 318],
        [ 323],
        [ 324],
        [ 328],
        [ 332],
        [ 340],
        [ 343],
        [ 360],
        [ 371],
        [ 376],
        [ 378],
        [ 385],
        [ 412],
        [ 416],
        [ 419],
        [ 423],
        [ 426],
        [ 434],
        [ 439],
        [ 446],
        [ 459],
        [ 463],
        [ 466],
        [ 469],
        [ 472],
        [ 477],
        [ 483],
        [ 484],
        [ 491],
        [ 501],
        [ 502],
        [ 504],
        [ 513],
        [ 515],
        [ 520],
        [ 524],
        [ 527],
        [ 530],
        [ 532],
        [ 534],
        [ 536],
        [ 537],
        [ 542],
        [ 543],
        [ 549],
        [ 566],
        [ 580],
        [ 597],
        [ 604],
        [ 613],
        [ 614],
        [ 620],
        [ 621],
        [ 625],
        [ 629],
        [ 632],
        [ 636],
        [ 638],
        [ 640],
        [ 642],
        [ 645],
        [ 649],
        [ 651],
        [ 653],
        [ 659],
        [ 660],
        [ 666],
        [ 675],
        [ 686],
        [ 689],
        [ 694],
        [ 711],
        [ 733],
        [ 737],
        [ 740],
        [ 752],
        [ 766],
        [ 815],
        [ 819],
        [ 822],
        [ 843],
        [ 850],
        [ 862],
        [ 885],
        [ 887],
        [ 900],
        [ 901],
        [ 913],
        [ 924],
        [ 931],
        [ 935],
        [ 947],
        [ 952],
        [ 962],
        [ 971],
        [ 980],
        [ 987],
        [ 991],
        [ 993],
        [ 997],
        [1000],
        [1016],
        [1024],
        [1029],
        [1044],
        [1045],
        [1050],
        [1052],
        [1055],
        [1065],
        [1067],
        [1077],
        [1100],
        [1115],
        [1127],
        [1129],
        [1146],
        [1175],
        [1178],
        [1189],
        [1192],
        [1218],
        [1225],
        [1228],
        [1232],
        [1235],
        [1239],
        [1254]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0004, grad_fn=<MeanBackward0>)
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(175., grad_fn=<SumBackward0>)
col loss indices --------- 5 ---------- tensor([[   0],
        [   3],
        [  10],
        [  13],
        [  15],
        [  23],
        [  33],
        [  35],
        [  39],
        [  47],
        [  63],
        [  66],
        [  69],
        [  70],
        [  75],
        [  76],
        [  85],
        [ 101],
        [ 108],
        [ 110],
        [ 113],
        [ 138],
        [ 154],
        [ 157],
        [ 158],
        [ 162],
        [ 175],
        [ 198],
        [ 201],
        [ 206],
        [ 208],
        [ 211],
        [ 213],
        [ 214],
        [ 216],
        [ 227],
        [ 228],
        [ 239],
        [ 248],
        [ 251],
        [ 262],
        [ 273],
        [ 274],
        [ 285],
        [ 290],
        [ 296],
        [ 310],
        [ 313],
        [ 333],
        [ 345],
        [ 356],
        [ 367],
        [ 373],
        [ 378],
        [ 383],
        [ 386],
        [ 390],
        [ 392],
        [ 395],
        [ 396],
        [ 404],
        [ 409],
        [ 429],
        [ 445],
        [ 452],
        [ 460],
        [ 470],
        [ 477],
        [ 480],
        [ 489],
        [ 492],
        [ 496],
        [ 506],
        [ 515],
        [ 521],
        [ 522],
        [ 523],
        [ 528],
        [ 532],
        [ 537],
        [ 541],
        [ 545],
        [ 548],
        [ 557],
        [ 558],
        [ 571],
        [ 578],
        [ 586],
        [ 596],
        [ 627],
        [ 630],
        [ 633],
        [ 636],
        [ 639],
        [ 640],
        [ 656],
        [ 661],
        [ 662],
        [ 681],
        [ 683],
        [ 685],
        [ 688],
        [ 694],
        [ 695],
        [ 704],
        [ 715],
        [ 716],
        [ 727],
        [ 763],
        [ 768],
        [ 771],
        [ 787],
        [ 788],
        [ 790],
        [ 794],
        [ 811],
        [ 819],
        [ 820],
        [ 834],
        [ 836],
        [ 838],
        [ 839],
        [ 841],
        [ 846],
        [ 853],
        [ 860],
        [ 863],
        [ 871],
        [ 877],
        [ 902],
        [ 903],
        [ 908],
        [ 911],
        [ 926],
        [ 927],
        [ 932],
        [ 934],
        [ 938],
        [ 963],
        [ 964],
        [ 966],
        [ 969],
        [ 986],
        [ 997],
        [1011],
        [1022],
        [1032],
        [1033],
        [1038],
        [1046],
        [1051],
        [1061],
        [1065],
        [1086],
        [1088],
        [1107],
        [1123],
        [1130],
        [1131],
        [1132],
        [1136],
        [1137],
        [1142],
        [1152],
        [1160],
        [1162],
        [1173],
        [1175],
        [1176],
        [1177],
        [1194],
        [1220],
        [1223],
        [1226],
        [1251]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0004, grad_fn=<MeanBackward0>)
Done -------------------------epoch  1
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(202., grad_fn=<SumBackward0>)
col loss indices --------- 0 ---------- tensor([[   1],
        [   6],
        [  26],
        [  30],
        [  38],
        [  43],
        [  45],
        [  47],
        [  50],
        [  56],
        [  58],
        [  61],
        [  64],
        [  71],
        [  73],
        [  89],
        [  97],
        [  98],
        [  99],
        [ 101],
        [ 103],
        [ 115],
        [ 122],
        [ 126],
        [ 128],
        [ 134],
        [ 144],
        [ 147],
        [ 162],
        [ 176],
        [ 184],
        [ 186],
        [ 187],
        [ 190],
        [ 202],
        [ 203],
        [ 206],
        [ 207],
        [ 228],
        [ 230],
        [ 240],
        [ 242],
        [ 244],
        [ 247],
        [ 261],
        [ 262],
        [ 264],
        [ 270],
        [ 274],
        [ 275],
        [ 294],
        [ 312],
        [ 328],
        [ 330],
        [ 344],
        [ 354],
        [ 384],
        [ 386],
        [ 405],
        [ 420],
        [ 430],
        [ 446],
        [ 454],
        [ 460],
        [ 461],
        [ 466],
        [ 474],
        [ 476],
        [ 486],
        [ 490],
        [ 496],
        [ 506],
        [ 511],
        [ 512],
        [ 513],
        [ 520],
        [ 530],
        [ 552],
        [ 557],
        [ 559],
        [ 561],
        [ 564],
        [ 577],
        [ 578],
        [ 580],
        [ 585],
        [ 590],
        [ 595],
        [ 600],
        [ 604],
        [ 605],
        [ 614],
        [ 619],
        [ 624],
        [ 627],
        [ 629],
        [ 631],
        [ 633],
        [ 639],
        [ 641],
        [ 642],
        [ 646],
        [ 649],
        [ 655],
        [ 667],
        [ 669],
        [ 673],
        [ 697],
        [ 700],
        [ 707],
        [ 720],
        [ 721],
        [ 730],
        [ 742],
        [ 745],
        [ 746],
        [ 761],
        [ 766],
        [ 774],
        [ 781],
        [ 790],
        [ 795],
        [ 814],
        [ 828],
        [ 840],
        [ 867],
        [ 869],
        [ 872],
        [ 879],
        [ 883],
        [ 908],
        [ 912],
        [ 913],
        [ 923],
        [ 929],
        [ 932],
        [ 933],
        [ 941],
        [ 946],
        [ 949],
        [ 950],
        [ 951],
        [ 954],
        [ 955],
        [ 970],
        [ 975],
        [ 977],
        [ 985],
        [ 994],
        [ 997],
        [1009],
        [1012],
        [1014],
        [1022],
        [1023],
        [1025],
        [1028],
        [1047],
        [1058],
        [1065],
        [1068],
        [1069],
        [1072],
        [1083],
        [1090],
        [1093],
        [1101],
        [1102],
        [1103],
        [1109],
        [1110],
        [1118],
        [1119],
        [1124],
        [1127],
        [1130],
        [1135],
        [1139],
        [1143],
        [1144],
        [1146],
        [1153],
        [1154],
        [1155],
        [1160],
        [1166],
        [1167],
        [1169],
        [1171],
        [1177],
        [1178],
        [1179],
        [1182],
        [1186],
        [1192],
        [1195],
        [1212],
        [1222],
        [1230],
        [1243],
        [1244],
        [1252]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0007, grad_fn=<MeanBackward0>)
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(193., grad_fn=<SumBackward0>)
col loss indices --------- 1 ---------- tensor([[   3],
        [   4],
        [  17],
        [  20],
        [  25],
        [  35],
        [  38],
        [  39],
        [  42],
        [  50],
        [  52],
        [  58],
        [  70],
        [  73],
        [  74],
        [  78],
        [  82],
        [  85],
        [  86],
        [  93],
        [  95],
        [ 102],
        [ 110],
        [ 113],
        [ 114],
        [ 136],
        [ 138],
        [ 140],
        [ 147],
        [ 150],
        [ 163],
        [ 164],
        [ 172],
        [ 201],
        [ 202],
        [ 211],
        [ 212],
        [ 214],
        [ 217],
        [ 226],
        [ 235],
        [ 244],
        [ 245],
        [ 247],
        [ 254],
        [ 273],
        [ 282],
        [ 286],
        [ 291],
        [ 316],
        [ 318],
        [ 321],
        [ 322],
        [ 327],
        [ 332],
        [ 347],
        [ 355],
        [ 365],
        [ 383],
        [ 395],
        [ 398],
        [ 404],
        [ 417],
        [ 427],
        [ 432],
        [ 443],
        [ 449],
        [ 450],
        [ 454],
        [ 460],
        [ 464],
        [ 467],
        [ 470],
        [ 475],
        [ 488],
        [ 492],
        [ 493],
        [ 525],
        [ 532],
        [ 536],
        [ 541],
        [ 543],
        [ 544],
        [ 548],
        [ 552],
        [ 554],
        [ 558],
        [ 559],
        [ 561],
        [ 564],
        [ 571],
        [ 574],
        [ 581],
        [ 592],
        [ 600],
        [ 602],
        [ 617],
        [ 619],
        [ 642],
        [ 652],
        [ 664],
        [ 674],
        [ 677],
        [ 679],
        [ 687],
        [ 688],
        [ 690],
        [ 695],
        [ 709],
        [ 710],
        [ 718],
        [ 720],
        [ 736],
        [ 746],
        [ 753],
        [ 756],
        [ 760],
        [ 766],
        [ 769],
        [ 776],
        [ 793],
        [ 795],
        [ 797],
        [ 798],
        [ 808],
        [ 809],
        [ 811],
        [ 814],
        [ 828],
        [ 835],
        [ 840],
        [ 843],
        [ 853],
        [ 855],
        [ 857],
        [ 871],
        [ 890],
        [ 893],
        [ 900],
        [ 905],
        [ 907],
        [ 914],
        [ 921],
        [ 931],
        [ 954],
        [ 955],
        [ 959],
        [ 967],
        [ 968],
        [ 970],
        [ 976],
        [ 978],
        [ 979],
        [ 980],
        [ 987],
        [ 992],
        [1000],
        [1004],
        [1015],
        [1016],
        [1021],
        [1034],
        [1037],
        [1041],
        [1046],
        [1052],
        [1059],
        [1067],
        [1075],
        [1076],
        [1078],
        [1083],
        [1086],
        [1101],
        [1103],
        [1104],
        [1105],
        [1114],
        [1122],
        [1132],
        [1138],
        [1149],
        [1159],
        [1163],
        [1168],
        [1172],
        [1178],
        [1194],
        [1202],
        [1204],
        [1206],
        [1228],
        [1237]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0004, grad_fn=<MeanBackward0>)
Mode ----------- label
target cols: ---------- [2]
number of predicted values: ---------- tensor(224., grad_fn=<SumBackward0>)
col loss indices --------- 2 ---------- tensor([[   2],
        [   4],
        [  11],
        [  12],
        [  15],
        [  16],
        [  23],
        [  25],
        [  41],
        [  46],
        [  51],
        [  54],
        [  59],
        [  68],
        [  74],
        [  96],
        [ 103],
        [ 105],
        [ 110],
        [ 111],
        [ 112],
        [ 135],
        [ 140],
        [ 146],
        [ 153],
        [ 155],
        [ 162],
        [ 167],
        [ 173],
        [ 175],
        [ 182],
        [ 185],
        [ 186],
        [ 188],
        [ 199],
        [ 203],
        [ 215],
        [ 226],
        [ 238],
        [ 239],
        [ 241],
        [ 242],
        [ 244],
        [ 245],
        [ 246],
        [ 260],
        [ 264],
        [ 276],
        [ 277],
        [ 288],
        [ 289],
        [ 290],
        [ 295],
        [ 297],
        [ 300],
        [ 313],
        [ 330],
        [ 334],
        [ 337],
        [ 341],
        [ 349],
        [ 350],
        [ 356],
        [ 361],
        [ 362],
        [ 363],
        [ 367],
        [ 369],
        [ 374],
        [ 376],
        [ 380],
        [ 385],
        [ 394],
        [ 397],
        [ 399],
        [ 405],
        [ 408],
        [ 415],
        [ 431],
        [ 434],
        [ 435],
        [ 437],
        [ 441],
        [ 449],
        [ 466],
        [ 470],
        [ 472],
        [ 479],
        [ 480],
        [ 483],
        [ 489],
        [ 491],
        [ 511],
        [ 520],
        [ 534],
        [ 539],
        [ 543],
        [ 544],
        [ 551],
        [ 557],
        [ 577],
        [ 590],
        [ 591],
        [ 592],
        [ 598],
        [ 599],
        [ 606],
        [ 608],
        [ 610],
        [ 620],
        [ 622],
        [ 629],
        [ 635],
        [ 637],
        [ 660],
        [ 665],
        [ 668],
        [ 675],
        [ 678],
        [ 680],
        [ 686],
        [ 687],
        [ 693],
        [ 698],
        [ 699],
        [ 705],
        [ 711],
        [ 713],
        [ 715],
        [ 725],
        [ 732],
        [ 735],
        [ 736],
        [ 746],
        [ 757],
        [ 762],
        [ 779],
        [ 781],
        [ 793],
        [ 800],
        [ 801],
        [ 802],
        [ 810],
        [ 811],
        [ 813],
        [ 817],
        [ 821],
        [ 823],
        [ 830],
        [ 847],
        [ 850],
        [ 854],
        [ 856],
        [ 860],
        [ 872],
        [ 876],
        [ 886],
        [ 888],
        [ 903],
        [ 909],
        [ 920],
        [ 921],
        [ 923],
        [ 925],
        [ 941],
        [ 950],
        [ 952],
        [ 959],
        [ 960],
        [ 963],
        [ 971],
        [ 982],
        [ 983],
        [ 986],
        [ 995],
        [ 997],
        [1000],
        [1010],
        [1011],
        [1014],
        [1018],
        [1021],
        [1025],
        [1027],
        [1030],
        [1033],
        [1038],
        [1046],
        [1056],
        [1057],
        [1063],
        [1068],
        [1073],
        [1081],
        [1087],
        [1088],
        [1090],
        [1097],
        [1106],
        [1109],
        [1117],
        [1125],
        [1130],
        [1131],
        [1136],
        [1155],
        [1159],
        [1165],
        [1179],
        [1181],
        [1184],
        [1191],
        [1195],
        [1200],
        [1202],
        [1212],
        [1213],
        [1216],
        [1220],
        [1230],
        [1238],
        [1241],
        [1244],
        [1248]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0006, grad_fn=<MeanBackward0>)
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(0., grad_fn=<SumBackward0>)
col loss indices --------- 2 ---------- tensor([], size=(0, 1), dtype=torch.int64)
Computing PINNs Loss:
Physics Loss:  tensor(0.0006, grad_fn=<MeanBackward0>)
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(175., grad_fn=<SumBackward0>)
col loss indices --------- 3 ---------- tensor([[   9],
        [  11],
        [  14],
        [  16],
        [  20],
        [  22],
        [  25],
        [  30],
        [  40],
        [  42],
        [  47],
        [  56],
        [  59],
        [  62],
        [  63],
        [  77],
        [  84],
        [  97],
        [ 102],
        [ 104],
        [ 108],
        [ 131],
        [ 132],
        [ 161],
        [ 168],
        [ 172],
        [ 176],
        [ 180],
        [ 181],
        [ 183],
        [ 186],
        [ 187],
        [ 202],
        [ 214],
        [ 221],
        [ 253],
        [ 260],
        [ 261],
        [ 264],
        [ 267],
        [ 273],
        [ 274],
        [ 288],
        [ 290],
        [ 303],
        [ 304],
        [ 326],
        [ 332],
        [ 350],
        [ 362],
        [ 369],
        [ 372],
        [ 383],
        [ 385],
        [ 392],
        [ 397],
        [ 400],
        [ 405],
        [ 411],
        [ 424],
        [ 425],
        [ 429],
        [ 435],
        [ 446],
        [ 450],
        [ 451],
        [ 452],
        [ 453],
        [ 461],
        [ 462],
        [ 486],
        [ 509],
        [ 513],
        [ 532],
        [ 535],
        [ 542],
        [ 551],
        [ 560],
        [ 561],
        [ 566],
        [ 571],
        [ 576],
        [ 577],
        [ 586],
        [ 591],
        [ 608],
        [ 619],
        [ 621],
        [ 622],
        [ 623],
        [ 651],
        [ 664],
        [ 666],
        [ 689],
        [ 692],
        [ 712],
        [ 716],
        [ 718],
        [ 725],
        [ 733],
        [ 742],
        [ 752],
        [ 766],
        [ 767],
        [ 769],
        [ 777],
        [ 779],
        [ 785],
        [ 791],
        [ 799],
        [ 800],
        [ 804],
        [ 832],
        [ 840],
        [ 847],
        [ 851],
        [ 856],
        [ 864],
        [ 867],
        [ 875],
        [ 880],
        [ 889],
        [ 897],
        [ 903],
        [ 913],
        [ 915],
        [ 920],
        [ 940],
        [ 947],
        [ 949],
        [ 957],
        [ 969],
        [ 972],
        [ 978],
        [1004],
        [1019],
        [1020],
        [1021],
        [1033],
        [1034],
        [1044],
        [1055],
        [1063],
        [1066],
        [1067],
        [1078],
        [1080],
        [1083],
        [1092],
        [1094],
        [1095],
        [1099],
        [1105],
        [1107],
        [1111],
        [1123],
        [1132],
        [1141],
        [1146],
        [1148],
        [1149],
        [1153],
        [1184],
        [1187],
        [1192],
        [1196],
        [1207],
        [1208],
        [1216],
        [1219],
        [1227],
        [1237],
        [1239],
        [1242],
        [1244]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0004, grad_fn=<MeanBackward0>)
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(188., grad_fn=<SumBackward0>)
col loss indices --------- 4 ---------- tensor([[   0],
        [  17],
        [  24],
        [  25],
        [  33],
        [  36],
        [  40],
        [  42],
        [  45],
        [  58],
        [  67],
        [  76],
        [  80],
        [  84],
        [  95],
        [  99],
        [ 103],
        [ 104],
        [ 109],
        [ 137],
        [ 141],
        [ 145],
        [ 155],
        [ 160],
        [ 162],
        [ 165],
        [ 180],
        [ 182],
        [ 184],
        [ 192],
        [ 221],
        [ 224],
        [ 232],
        [ 233],
        [ 242],
        [ 252],
        [ 265],
        [ 266],
        [ 271],
        [ 274],
        [ 275],
        [ 278],
        [ 290],
        [ 297],
        [ 306],
        [ 318],
        [ 325],
        [ 327],
        [ 336],
        [ 353],
        [ 355],
        [ 357],
        [ 360],
        [ 361],
        [ 370],
        [ 374],
        [ 382],
        [ 383],
        [ 386],
        [ 389],
        [ 397],
        [ 398],
        [ 423],
        [ 429],
        [ 436],
        [ 438],
        [ 442],
        [ 450],
        [ 464],
        [ 481],
        [ 491],
        [ 495],
        [ 521],
        [ 528],
        [ 532],
        [ 536],
        [ 545],
        [ 548],
        [ 556],
        [ 562],
        [ 568],
        [ 581],
        [ 582],
        [ 583],
        [ 587],
        [ 589],
        [ 591],
        [ 599],
        [ 602],
        [ 608],
        [ 638],
        [ 641],
        [ 642],
        [ 648],
        [ 653],
        [ 660],
        [ 662],
        [ 674],
        [ 686],
        [ 687],
        [ 690],
        [ 693],
        [ 698],
        [ 702],
        [ 716],
        [ 723],
        [ 740],
        [ 746],
        [ 750],
        [ 764],
        [ 767],
        [ 769],
        [ 782],
        [ 783],
        [ 790],
        [ 795],
        [ 798],
        [ 799],
        [ 802],
        [ 829],
        [ 831],
        [ 849],
        [ 856],
        [ 857],
        [ 865],
        [ 866],
        [ 870],
        [ 875],
        [ 876],
        [ 886],
        [ 888],
        [ 898],
        [ 903],
        [ 904],
        [ 909],
        [ 925],
        [ 933],
        [ 935],
        [ 937],
        [ 940],
        [ 945],
        [ 952],
        [ 961],
        [ 969],
        [ 970],
        [ 980],
        [ 981],
        [ 982],
        [ 986],
        [ 989],
        [ 996],
        [1000],
        [1002],
        [1012],
        [1023],
        [1032],
        [1036],
        [1037],
        [1047],
        [1055],
        [1060],
        [1064],
        [1074],
        [1083],
        [1086],
        [1095],
        [1098],
        [1110],
        [1126],
        [1141],
        [1142],
        [1145],
        [1152],
        [1164],
        [1169],
        [1170],
        [1177],
        [1196],
        [1198],
        [1207],
        [1221],
        [1223],
        [1226],
        [1236],
        [1239],
        [1250],
        [1254],
        [1255]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0005, grad_fn=<MeanBackward0>)
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(191., grad_fn=<SumBackward0>)
col loss indices --------- 5 ---------- tensor([[   0],
        [   3],
        [   8],
        [  16],
        [  19],
        [  25],
        [  27],
        [  29],
        [  33],
        [  38],
        [  44],
        [  45],
        [  49],
        [  60],
        [  62],
        [  67],
        [  68],
        [  75],
        [  81],
        [  86],
        [  90],
        [ 101],
        [ 102],
        [ 125],
        [ 132],
        [ 139],
        [ 141],
        [ 155],
        [ 166],
        [ 176],
        [ 182],
        [ 193],
        [ 206],
        [ 212],
        [ 223],
        [ 239],
        [ 253],
        [ 258],
        [ 272],
        [ 291],
        [ 302],
        [ 303],
        [ 304],
        [ 306],
        [ 324],
        [ 331],
        [ 334],
        [ 336],
        [ 340],
        [ 347],
        [ 359],
        [ 363],
        [ 365],
        [ 373],
        [ 377],
        [ 379],
        [ 385],
        [ 397],
        [ 407],
        [ 413],
        [ 416],
        [ 419],
        [ 424],
        [ 430],
        [ 434],
        [ 440],
        [ 453],
        [ 458],
        [ 461],
        [ 463],
        [ 466],
        [ 467],
        [ 471],
        [ 480],
        [ 484],
        [ 486],
        [ 487],
        [ 501],
        [ 503],
        [ 515],
        [ 517],
        [ 522],
        [ 525],
        [ 535],
        [ 543],
        [ 549],
        [ 557],
        [ 573],
        [ 574],
        [ 581],
        [ 592],
        [ 601],
        [ 609],
        [ 610],
        [ 614],
        [ 623],
        [ 630],
        [ 634],
        [ 638],
        [ 640],
        [ 646],
        [ 657],
        [ 667],
        [ 703],
        [ 707],
        [ 713],
        [ 716],
        [ 717],
        [ 723],
        [ 736],
        [ 738],
        [ 743],
        [ 749],
        [ 752],
        [ 756],
        [ 757],
        [ 780],
        [ 784],
        [ 786],
        [ 792],
        [ 804],
        [ 805],
        [ 810],
        [ 811],
        [ 812],
        [ 817],
        [ 820],
        [ 825],
        [ 829],
        [ 830],
        [ 833],
        [ 840],
        [ 863],
        [ 866],
        [ 869],
        [ 885],
        [ 898],
        [ 900],
        [ 903],
        [ 906],
        [ 915],
        [ 924],
        [ 939],
        [ 941],
        [ 944],
        [ 950],
        [ 952],
        [ 954],
        [ 955],
        [ 961],
        [ 965],
        [ 981],
        [ 983],
        [ 998],
        [1000],
        [1005],
        [1010],
        [1016],
        [1018],
        [1030],
        [1044],
        [1047],
        [1054],
        [1055],
        [1056],
        [1057],
        [1059],
        [1072],
        [1078],
        [1084],
        [1089],
        [1098],
        [1100],
        [1105],
        [1106],
        [1117],
        [1138],
        [1140],
        [1150],
        [1170],
        [1171],
        [1188],
        [1204],
        [1209],
        [1212],
        [1226],
        [1229],
        [1235],
        [1246],
        [1247],
        [1253]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0004, grad_fn=<MeanBackward0>)
Done -------------------------epoch  2
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(194., grad_fn=<SumBackward0>)
col loss indices --------- 0 ---------- tensor([[   2],
        [   4],
        [  20],
        [  24],
        [  34],
        [  40],
        [  44],
        [  47],
        [  50],
        [  63],
        [  64],
        [  66],
        [  73],
        [  77],
        [  80],
        [  81],
        [  87],
        [ 117],
        [ 124],
        [ 128],
        [ 147],
        [ 150],
        [ 173],
        [ 181],
        [ 190],
        [ 194],
        [ 196],
        [ 206],
        [ 207],
        [ 210],
        [ 219],
        [ 222],
        [ 229],
        [ 238],
        [ 243],
        [ 252],
        [ 257],
        [ 268],
        [ 276],
        [ 277],
        [ 283],
        [ 288],
        [ 297],
        [ 316],
        [ 317],
        [ 318],
        [ 319],
        [ 327],
        [ 329],
        [ 342],
        [ 349],
        [ 366],
        [ 375],
        [ 386],
        [ 388],
        [ 396],
        [ 402],
        [ 407],
        [ 411],
        [ 416],
        [ 417],
        [ 418],
        [ 421],
        [ 423],
        [ 439],
        [ 440],
        [ 448],
        [ 450],
        [ 451],
        [ 455],
        [ 464],
        [ 469],
        [ 477],
        [ 480],
        [ 482],
        [ 490],
        [ 514],
        [ 519],
        [ 527],
        [ 529],
        [ 533],
        [ 544],
        [ 554],
        [ 558],
        [ 564],
        [ 565],
        [ 566],
        [ 567],
        [ 568],
        [ 573],
        [ 576],
        [ 577],
        [ 591],
        [ 594],
        [ 600],
        [ 607],
        [ 611],
        [ 612],
        [ 613],
        [ 614],
        [ 627],
        [ 633],
        [ 640],
        [ 646],
        [ 653],
        [ 656],
        [ 658],
        [ 659],
        [ 663],
        [ 669],
        [ 675],
        [ 677],
        [ 686],
        [ 690],
        [ 699],
        [ 702],
        [ 711],
        [ 717],
        [ 722],
        [ 724],
        [ 740],
        [ 741],
        [ 742],
        [ 747],
        [ 764],
        [ 766],
        [ 784],
        [ 798],
        [ 799],
        [ 802],
        [ 804],
        [ 812],
        [ 822],
        [ 826],
        [ 832],
        [ 834],
        [ 839],
        [ 843],
        [ 873],
        [ 875],
        [ 876],
        [ 879],
        [ 887],
        [ 899],
        [ 901],
        [ 905],
        [ 906],
        [ 908],
        [ 912],
        [ 913],
        [ 923],
        [ 924],
        [ 927],
        [ 943],
        [ 944],
        [ 953],
        [ 975],
        [ 976],
        [ 984],
        [ 988],
        [1006],
        [1012],
        [1028],
        [1041],
        [1042],
        [1051],
        [1060],
        [1061],
        [1078],
        [1080],
        [1085],
        [1094],
        [1111],
        [1115],
        [1116],
        [1118],
        [1122],
        [1126],
        [1129],
        [1135],
        [1138],
        [1142],
        [1155],
        [1174],
        [1197],
        [1201],
        [1203],
        [1205],
        [1211],
        [1214],
        [1219],
        [1228],
        [1229],
        [1236]])
Computing PINNs Loss:
Physics Loss:  tensor(0.0006, grad_fn=<MeanBackward0>)
Mode ----------- augmentation
target cols: ---------- [2]
number of predicted values: ---------- tensor(191., grad_fn=<SumBackward0>)
col loss indices --------- 1 ---------- tensor([[   4],
        [  18],
        [  19],
        [  30],
        [  34],
        [  44],
        [  53],
        [  58],
        [  61],
        [  68],
        [  74],
        [  87],
        [  98],
        [ 103],
        [ 107],
        [ 108],
        [ 121],
        [ 136],
        [ 139],
        [ 144],
        [ 163],
        [ 171],
        [ 173],
        [ 174],
        [ 185],
        [ 187],
        [ 192],
        [ 193],
        [ 197],
        [ 210],
        [ 211],
        [ 225],
        [ 226],
        [ 240],
        [ 242],
        [ 244],
        [ 245],
        [ 256],
        [ 262],
        [ 271],
        [ 307],
        [ 308],
        [ 316],
        [ 326],
        [ 327],
        [ 330],
        [ 333],
        [ 366],
        [ 377],
        [ 380],
        [ 384],
        [ 387],
        [ 392],
        [ 396],
        [ 401],
        [ 407],
        [ 414],
        [ 422],
        [ 426],
        [ 430],
        [ 433],
        [ 436],
        [ 439],
        [ 440],
        [ 443],
        [ 453],
        [ 458],
        [ 461],
        [ 471],
        [ 474],
        [ 491],
        [ 495],
        [ 517],
        [ 521],
        [ 526],
        [ 528],
        [ 529],
        [ 531],
        [ 532],
        [ 541],
        [ 544],
        [ 555],
        [ 568],
        [ 576],
        [ 595],
        [ 599],
        [ 607],
        [ 619],
        [ 624],
        [ 628],
        [ 629],
        [ 633],
        [ 635],
        [ 642],
        [ 645],
        [ 646],
        [ 652],
        [ 656],
        [ 665],
        [ 668],
        [ 669],
        [ 673],
        [ 684],
        [ 691],
        [ 692],
        [ 699],
        [ 708],
        [ 714],
        [ 717],
        [ 718],
        [ 719],
        [ 724],
        [ 745],
        [ 747],
        [ 754],
        [ 760],
        [ 775],
        [ 784],
        [ 790],
        [ 798],
        [ 801],
        [ 808],
        [ 810],
        [ 811],
        [ 814],
        [ 819],
        [ 820],
        [ 831],
        [ 842],
        [ 847],
        [ 849],
        [ 855],
        [ 868],
        [ 875],
        [ 876],
        [ 883],
        [ 886],
        [ 890],
        [ 893],
        [ 907],
        [ 908],
        [ 912],
        [ 916],
        [ 923],
        [ 925],
        [ 927],
        [ 951],
        [ 952],
        [ 960],
        [ 965],
        [ 978],
        [ 981],
        [ 983],
        [ 989],
        [ 990],
        [ 991],
        [ 998],
        [1010],
        [1011],
        [1012],
        [1023],
        [1030],
        [1041],
        [1069],
        [1075],
        [1081],
        [1103],
        [1104],
        [1108],
        [1110],
        [1112],
        [1114],
        [1120],
        [1124],
        [1140],
        [1144],
        [1161],
        [1168],
        [1176],
        [1186],
        [1189],
        [1190],
        [1205],
        [1211],
        [1217],
        [1227],
        [1232],
        [1237],
        [1239],
        [1241],
        [1255]])
