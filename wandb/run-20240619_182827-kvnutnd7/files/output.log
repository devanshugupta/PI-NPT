Disabling AUROC metric.
	Because dataset has 0 =/= 1 categorical target columns.
Loaded metadata for fixed test set. n_cv_splits set to 1.
Fixed test set provided. n_cv_splits set to 1.
Percentage of each group: Train 0.18 | Val 0.03 | Test 0.80
train val test split:  [   0  224  256 1256]
mask matrices --------------------
[[False False False False False False]
 [False False  True False False False]
 [False False False False False False]
 ...
 [False False False False False False]
 [False False False False False False]
 [False False False False False False]] [[False False False False False False]
 [False False False False False False]
 [False False False False False False]
 ...
 [False False False False False False]
 [False False False False False False]
 [False False False False False False]] [[False False False False False False]
 [False False False False False False]
 [False False False False False False]
 ...
 [False False  True False False False]
 [False False  True False False False]
 [False False  True False False False]]
----------------------------------
new missing matrix ------------- [[False False False False False False]
 [False False  True False False False]
 [False False False False False False]
 ...
 [False False  True False False False]
 [False False  True False False False]
 [False False  True False False False]]
metadata {'N': 1256, 'D': 6, 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'cat_target_cols': [], 'num_target_cols': [2], 'input_feature_dims': [2, 2, 2, 2, 2, 2], 'fixed_test_set_index': 256, 'auroc_setting': False}
CV Index: 0
Train-test Split 1/1
Building NPT.
All features are either categorical or numerical. Not going to bother doing feature type embeddings.
Using feature type embedding (unique embedding for categorical and numerical features).
Using feature index embedding (unique embedding for each column).
Clipping gradients to value 1.0.
Model has 31576838 parameters,batch size -1.
Initialized "lookahead_lamb" optimizer.
Warming up for 70000.0/100000.0 steps.
Initialized "flat_and_anneal" learning rate scheduler.
Initialized "cosine" augmentation/label tradeoff annealer. Annealing to minimum value in 100000 steps.
Disabled AUROC in loss module.
end_experiment or self.eval_check(epoch) False False
batch_dataset coming from self.dataset_gen ------- <npt.batch_dataset.NPTBatchDataset object at 0x327f11130>
data dict | train.py run_epoch() ---- {'train_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[ 0.2597,  0.0000],
        [-0.3620,  0.0000],
        [-1.0378,  0.0000],
        ...,
        [-1.1189,  0.0000],
        [-0.0106,  0.0000],
        [ 1.4626,  0.0000]], requires_grad=True), tensor([[ 1.8207,  0.0000],
        [-1.2226,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [-1.0689,  0.0000],
        [-1.0074,  0.0000],
        [-0.3004,  0.0000]], requires_grad=True), tensor([[0.0000, 1.0000],
        [0.8452, 0.0000],
        [1.3159, 0.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[ 0.2597,  0.0000],
        [-0.3620,  0.0000],
        [-1.0378,  0.0000],
        ...,
        [-1.1189,  0.0000],
        [-0.0106,  0.0000],
        [ 1.4626,  0.0000]], requires_grad=True), tensor([[ 1.8207,  0.0000],
        [-1.2226,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [-1.0689,  0.0000],
        [-1.0074,  0.0000],
        [-0.3004,  0.0000]], requires_grad=True), tensor([[0.0000, 1.0000],
        [0.8452, 0.0000],
        [1.3159, 0.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 1.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 1.],
        [0., 0.]], requires_grad=True), tensor([[0., 1.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[0., 0., 0., 0., 1., 1.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)}
Dataset mode -----  train
data dict | loss.py compute_loss() -------- {'train_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[ 0.2597,  0.0000],
        [-0.3620,  0.0000],
        [-1.0378,  0.0000],
        ...,
        [-1.1189,  0.0000],
        [-0.0106,  0.0000],
        [ 1.4626,  0.0000]], requires_grad=True), tensor([[ 1.8207,  0.0000],
        [-1.2226,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [-1.0689,  0.0000],
        [-1.0074,  0.0000],
        [-0.3004,  0.0000]], requires_grad=True), tensor([[0.0000, 1.0000],
        [0.8452, 0.0000],
        [1.3159, 0.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[ 0.2597,  0.0000],
        [-0.3620,  0.0000],
        [-1.0378,  0.0000],
        ...,
        [-1.1189,  0.0000],
        [-0.0106,  0.0000],
        [ 1.4626,  0.0000]], requires_grad=True), tensor([[ 1.8207,  0.0000],
        [-1.2226,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [-1.0689,  0.0000],
        [-1.0074,  0.0000],
        [-0.3004,  0.0000]], requires_grad=True), tensor([[0.0000, 1.0000],
        [0.8452, 0.0000],
        [1.3159, 0.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 1.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 1.],
        [0., 0.]], requires_grad=True), tensor([[0., 1.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[0., 0., 0., 0., 1., 1.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)}
/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/Users/devu/PycharmProjects/non-parametric-transformers/npt/mask.py:108: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403207619/work/torch/csrc/utils/tensor_new.cpp:620.)
  mask = torch.sparse.FloatTensor(
Physics Loss:  tensor(0.0004, grad_fn=<MeanBackward0>)
Physics Loss:  tensor(0.0004, grad_fn=<MeanBackward0>)
Done -------------------------epoch  1
end_experiment or self.eval_check(epoch) False False
batch_dataset coming from self.dataset_gen ------- <npt.batch_dataset.NPTBatchDataset object at 0x327f11130>
data dict | train.py run_epoch() ---- {'train_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[-0.3215,  0.0000],
        [ 1.0977,  0.0000],
        [-1.4838,  0.0000],
        ...,
        [-0.0376,  0.0000],
        [ 0.0299,  0.0000],
        [-1.1189,  0.0000]], requires_grad=True), tensor([[-0.8230,  0.0000],
        [ 0.3144,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [ 0.0070,  0.0000],
        [-1.2226,  0.0000],
        [-1.2226,  0.0000]], requires_grad=True), tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.5810,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [-0.0901,  0.0000],
        [ 1.2366,  0.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[-0.3215,  0.0000],
        [ 1.0977,  0.0000],
        [-1.4838,  0.0000],
        ...,
        [-0.0376,  0.0000],
        [ 0.0299,  0.0000],
        [-1.1189,  0.0000]], requires_grad=True), tensor([[-0.8230,  0.0000],
        [ 0.3144,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [ 0.0070,  0.0000],
        [-1.2226,  0.0000],
        [-1.2226,  0.0000]], requires_grad=True), tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.5810,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [-0.0901,  0.0000],
        [ 1.2366,  0.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[-0.0894,  0.0000],
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[0., 0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)}
Dataset mode -----  train
data dict | loss.py compute_loss() -------- {'train_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[-0.3215,  0.0000],
        [ 1.0977,  0.0000],
        [-1.4838,  0.0000],
        ...,
        [-0.0376,  0.0000],
        [ 0.0299,  0.0000],
        [-1.1189,  0.0000]], requires_grad=True), tensor([[-0.8230,  0.0000],
        [ 0.3144,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [ 0.0070,  0.0000],
        [-1.2226,  0.0000],
        [-1.2226,  0.0000]], requires_grad=True), tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.5810,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [-0.0901,  0.0000],
        [ 1.2366,  0.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[-0.3215,  0.0000],
        [ 1.0977,  0.0000],
        [-1.4838,  0.0000],
        ...,
        [-0.0376,  0.0000],
        [ 0.0299,  0.0000],
        [-1.1189,  0.0000]], requires_grad=True), tensor([[-0.8230,  0.0000],
        [ 0.3144,  0.0000],
        [-1.2226,  0.0000],
        ...,
        [ 0.0070,  0.0000],
        [-1.2226,  0.0000],
        [-1.2226,  0.0000]], requires_grad=True), tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.5810,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [-0.0901,  0.0000],
        [ 1.2366,  0.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[-0.0894,  0.0000],
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[0., 0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)}
Physics Loss:  tensor(0.0003, grad_fn=<MeanBackward0>)
Physics Loss:  tensor(0.0003, grad_fn=<MeanBackward0>)
Done -------------------------epoch  2
end_experiment or self.eval_check(epoch) False False
batch_dataset coming from self.dataset_gen ------- <npt.batch_dataset.NPTBatchDataset object at 0x327f11130>
data dict | train.py run_epoch() ---- {'train_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[ 0.6922,  0.0000],
        [-1.0108,  0.0000],
        [-0.9161,  0.0000],
        ...,
        [-0.8215,  0.0000],
        [-1.4432,  0.0000],
        [-0.9432,  0.0000]], requires_grad=True), tensor([[ 1.1137,  0.0000],
        [-1.2226,  0.0000],
        [-0.6386,  0.0000],
        ...,
        [-1.2226,  0.0000],
        [ 1.4826,  0.0000],
        [ 0.4374,  0.0000]], requires_grad=True), tensor([[0.0000, 1.0000],
        [1.3360, 0.0000],
        [0.0000, 1.0000],
        ...,
        [1.3831, 0.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[ 0.6922,  0.0000],
        [ 1.2405,  0.0000],
        [-0.9161,  0.0000],
        ...,
        [-0.8215,  0.0000],
        [-1.4432,  0.0000],
        [-0.9432,  0.0000]], requires_grad=True), tensor([[ 1.1137,  0.0000],
        [-1.2226,  0.0000],
        [-0.6386,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 1.4826,  0.0000],
        [ 0.4374,  0.0000]], requires_grad=True), tensor([[0.0000, 1.0000],
        [1.3360, 0.0000],
        [0.0000, 1.0000],
        ...,
        [1.3831, 0.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[ 0.0000,  0.0000],
        [-2.2389,  0.0000],
        [ 0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  0.0000]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [1., 0., 0., 0., 1., 1.],
        [0., 0., 0., 0., 1., 0.],
        ...,
        [0., 1., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)}
Dataset mode -----  train
data dict | loss.py compute_loss() -------- {'train_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[ 0.6922,  0.0000],
        [-1.0108,  0.0000],
        [-0.9161,  0.0000],
        ...,
        [-0.8215,  0.0000],
        [-1.4432,  0.0000],
        [-0.9432,  0.0000]], requires_grad=True), tensor([[ 1.1137,  0.0000],
        [-1.2226,  0.0000],
        [-0.6386,  0.0000],
        ...,
        [-1.2226,  0.0000],
        [ 1.4826,  0.0000],
        [ 0.4374,  0.0000]], requires_grad=True), tensor([[0.0000, 1.0000],
        [1.3360, 0.0000],
        [0.0000, 1.0000],
        ...,
        [1.3831, 0.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[ 0.6922,  0.0000],
        [ 1.2405,  0.0000],
        [-0.9161,  0.0000],
        ...,
        [-0.8215,  0.0000],
        [-1.4432,  0.0000],
        [-0.9432,  0.0000]], requires_grad=True), tensor([[ 1.1137,  0.0000],
        [-1.2226,  0.0000],
        [-0.6386,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 1.4826,  0.0000],
        [ 0.4374,  0.0000]], requires_grad=True), tensor([[0.0000, 1.0000],
        [1.3360, 0.0000],
        [0.0000, 1.0000],
        ...,
        [1.3831, 0.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[ 0.0000,  0.0000],
        [-2.2389,  0.0000],
        [ 0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  0.0000]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [1., 0., 0., 0., 1., 1.],
        [0., 0., 0., 0., 1., 0.],
        ...,
        [0., 1., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)}
Physics Loss:  tensor(0.0003, grad_fn=<MeanBackward0>)
Physics Loss:  tensor(0.0003, grad_fn=<MeanBackward0>)
Done -------------------------epoch  3
end_experiment or self.eval_check(epoch) False False
batch_dataset coming from self.dataset_gen ------- <npt.batch_dataset.NPTBatchDataset object at 0x327f11130>
data dict | train.py run_epoch() ---- {'train_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[-0.6999,  0.0000],
        [ 0.7598,  0.0000],
        [ 1.2463,  0.0000],
        ...,
        [ 0.3813,  0.0000],
        [-1.4838,  0.0000],
        [-0.9297,  0.0000]], requires_grad=True), tensor([[ 0.6218,  0.0000],
        [-1.2226,  0.0000],
        [-0.2082,  0.0000],
        ...,
        [-1.2226,  0.0000],
        [-1.2226,  0.0000],
        [ 1.4826,  0.0000]], requires_grad=True), tensor([[ 0.0000,  1.0000],
        [-1.4020,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [-0.9142,  0.0000],
        [ 0.5810,  0.0000],
        [ 0.0000,  1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[-0.6999,  0.0000],
        [ 0.7598,  0.0000],
        [ 1.2463,  0.0000],
        ...,
        [ 0.3813,  0.0000],
        [-1.4838,  0.0000],
        [-0.9297,  0.0000]], requires_grad=True), tensor([[ 0.6218,  0.0000],
        [-1.2226,  0.0000],
        [-0.2082,  0.0000],
        ...,
        [-1.2226,  0.0000],
        [-1.2226,  0.0000],
        [ 1.4826,  0.0000]], requires_grad=True), tensor([[ 0.0000,  1.0000],
        [-1.4020,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [-0.9142,  0.0000],
        [ 0.5810,  0.0000],
        [ 0.0000,  1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 1.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1.],
        ...,
        [0., 0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)}
Dataset mode -----  train
data dict | loss.py compute_loss() -------- {'train_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[-0.6999,  0.0000],
        [ 0.7598,  0.0000],
        [ 1.2463,  0.0000],
        ...,
        [ 0.3813,  0.0000],
        [-1.4838,  0.0000],
        [-0.9297,  0.0000]], requires_grad=True), tensor([[ 0.6218,  0.0000],
        [-1.2226,  0.0000],
        [-0.2082,  0.0000],
        ...,
        [-1.2226,  0.0000],
        [-1.2226,  0.0000],
        [ 1.4826,  0.0000]], requires_grad=True), tensor([[ 0.0000,  1.0000],
        [-1.4020,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [-0.9142,  0.0000],
        [ 0.5810,  0.0000],
        [ 0.0000,  1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[-0.6999,  0.0000],
        [ 0.7598,  0.0000],
        [ 1.2463,  0.0000],
        ...,
        [ 0.3813,  0.0000],
        [-1.4838,  0.0000],
        [-0.9297,  0.0000]], requires_grad=True), tensor([[ 0.6218,  0.0000],
        [-1.2226,  0.0000],
        [-0.2082,  0.0000],
        ...,
        [-1.2226,  0.0000],
        [-1.2226,  0.0000],
        [ 1.4826,  0.0000]], requires_grad=True), tensor([[ 0.0000,  1.0000],
        [-1.4020,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [-0.9142,  0.0000],
        [ 0.5810,  0.0000],
        [ 0.0000,  1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 1.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1.],
        ...,
        [0., 0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)}
Physics Loss:  tensor(0.0004, grad_fn=<MeanBackward0>)
Physics Loss:  tensor(0.0004, grad_fn=<MeanBackward0>)
Done -------------------------epoch  4
end_experiment or self.eval_check(epoch) False True
batch_dataset coming from self.dataset_gen ------- <npt.batch_dataset.NPTBatchDataset object at 0x327f11130>
data dict | train.py run_epoch() ---- {'train_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[ 1.1247,  0.0000],
        [-1.5919,  0.0000],
        [-0.2944,  0.0000],
        ...,
        [-1.0378,  0.0000],
        [ 0.3813,  0.0000],
        [-0.4566,  0.0000]], requires_grad=True), tensor([[-1.2226,  0.0000],
        [-0.1467,  0.0000],
        [ 0.4374,  0.0000],
        ...,
        [ 0.4066,  0.0000],
        [ 1.2366,  0.0000],
        [-0.9152,  0.0000]], requires_grad=True), tensor([[-1.2787,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[ 1.1247,  0.0000],
        [-1.5919,  0.0000],
        [-0.2944,  0.0000],
        ...,
        [-1.0378,  0.0000],
        [ 0.3813,  0.0000],
        [-0.4566,  0.0000]], requires_grad=True), tensor([[-1.2226,  0.0000],
        [-0.1467,  0.0000],
        [-0.3754,  0.0000],
        ...,
        [ 0.4066,  0.0000],
        [ 1.2366,  0.0000],
        [ 0.0000,  1.0000]], requires_grad=True), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True), tensor([[0., 0.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0., 0.],
        [0., 1., 0., 1., 1., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 1., 0., 0., 0., 0.]], requires_grad=True)}
Dataset mode -----  train
data dict | loss.py compute_loss() -------- {'train_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[ 1.1247,  0.0000],
        [-1.5919,  0.0000],
        [-0.2944,  0.0000],
        ...,
        [-1.0378,  0.0000],
        [ 0.3813,  0.0000],
        [-0.4566,  0.0000]], requires_grad=True), tensor([[-1.2226,  0.0000],
        [-0.1467,  0.0000],
        [ 0.4374,  0.0000],
        ...,
        [ 0.4066,  0.0000],
        [ 1.2366,  0.0000],
        [-0.9152,  0.0000]], requires_grad=True), tensor([[-1.2787,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[ 1.1247,  0.0000],
        [-1.5919,  0.0000],
        [-0.2944,  0.0000],
        ...,
        [-1.0378,  0.0000],
        [ 0.3813,  0.0000],
        [-0.4566,  0.0000]], requires_grad=True), tensor([[-1.2226,  0.0000],
        [-0.1467,  0.0000],
        [-0.3754,  0.0000],
        ...,
        [ 0.4066,  0.0000],
        [ 1.2366,  0.0000],
        [ 0.0000,  1.0000]], requires_grad=True), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True), tensor([[0., 0.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 1.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': tensor([[0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0., 0.],
        [0., 1., 0., 1., 1., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 1., 0., 0., 0., 0.]], requires_grad=True)}
Physics Loss:  tensor(0.0006, grad_fn=<MeanBackward0>)
Physics Loss:  tensor(0.0006, grad_fn=<MeanBackward0>)
Done -------------------------epoch  5
batch_dataset coming from self.dataset_gen ------- <npt.batch_dataset.NPTBatchDataset object at 0x327f11130>
data dict | train.py run_epoch() ---- {'val_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[-0.7945,  0.0000],
        [ 1.6248,  0.0000],
        [ 1.0301,  0.0000],
        ...,
        [-1.0513,  0.0000],
        [ 0.5165,  0.0000],
        [-0.8621,  0.0000]], requires_grad=True), tensor([[ 1.6670,  0.0000],
        [ 1.7592,  0.0000],
        [ 0.0685,  0.0000],
        ...,
        [-0.4234,  0.0000],
        [-0.1467,  0.0000],
        [ 1.5440,  0.0000]], requires_grad=True), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[-0.7945,  0.0000],
        [ 1.6248,  0.0000],
        [ 1.0301,  0.0000],
        ...,
        [-1.0513,  0.0000],
        [ 0.5165,  0.0000],
        [-0.8621,  0.0000]], requires_grad=True), tensor([[ 1.6670,  0.0000],
        [ 1.7592,  0.0000],
        [ 0.0685,  0.0000],
        ...,
        [-0.4234,  0.0000],
        [-0.1467,  0.0000],
        [ 1.5440,  0.0000]], requires_grad=True), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': None}
Dataset mode -----  val
Traceback (most recent call last):
  File "run.py", line 204, in <module>
    main(args)
  File "run.py", line 23, in main
    run_cv(args=args, wandb_args=wandb_args)
  File "run.py", line 117, in run_cv
    run_cv_splits(wandb_args, args, c, wandb_run)
  File "run.py", line 195, in run_cv_splits
    trainer.train_and_eval()
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 216, in train_and_eval
    if self.per_epoch_train_eval(epoch=epoch):
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 175, in per_epoch_train_eval
    early_stop = self.eval_model(
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 229, in eval_model
    val_loss=val_loss['label']['total_loss'],
KeyError: 'total_loss'
Traceback (most recent call last):
  File "run.py", line 204, in <module>
    main(args)
  File "run.py", line 23, in main
    run_cv(args=args, wandb_args=wandb_args)
  File "run.py", line 117, in run_cv
    run_cv_splits(wandb_args, args, c, wandb_run)
  File "run.py", line 195, in run_cv_splits
    trainer.train_and_eval()
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 216, in train_and_eval
    if self.per_epoch_train_eval(epoch=epoch):
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 175, in per_epoch_train_eval
    early_stop = self.eval_model(
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 229, in eval_model
    val_loss=val_loss['label']['total_loss'],
KeyError: 'total_loss'
data dict | loss.py compute_loss() -------- {'val_mask_matrix': tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True), 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'data_arrs': [tensor([[-0.7945,  0.0000],
        [ 1.6248,  0.0000],
        [ 1.0301,  0.0000],
        ...,
        [-1.0513,  0.0000],
        [ 0.5165,  0.0000],
        [-0.8621,  0.0000]], requires_grad=True), tensor([[ 1.6670,  0.0000],
        [ 1.7592,  0.0000],
        [ 0.0685,  0.0000],
        ...,
        [-0.4234,  0.0000],
        [-0.1467,  0.0000],
        [ 1.5440,  0.0000]], requires_grad=True), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'masked_tensors': [tensor([[-0.7945,  0.0000],
        [ 1.6248,  0.0000],
        [ 1.0301,  0.0000],
        ...,
        [-1.0513,  0.0000],
        [ 0.5165,  0.0000],
        [-0.8621,  0.0000]], requires_grad=True), tensor([[ 1.6670,  0.0000],
        [ 1.7592,  0.0000],
        [ 0.0685,  0.0000],
        ...,
        [-0.4234,  0.0000],
        [-0.1467,  0.0000],
        [ 1.5440,  0.0000]], requires_grad=True), tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True), tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        ...,
        [0., 0.],
        [0., 0.],
        [0., 0.]], requires_grad=True)], 'target_cols': [2], 'sigmas': [1.8159747047679642, 0.32858701076537306, 0.7102359386173877, 1.0, 1.0, 1.0], 'label_mask_matrix': None, 'augmentation_mask_matrix': None}
Physics Loss:  0
Done -------------------------epoch  5