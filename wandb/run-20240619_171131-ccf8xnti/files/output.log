Disabling AUROC metric.
	Because dataset has 0 =/= 1 categorical target columns.
Loaded metadata for fixed test set. n_cv_splits set to 1.
Fixed test set provided. n_cv_splits set to 1.
Percentage of each group: Train 0.18 | Val 0.03 | Test 0.80
train val test split:  [   0  224  256 1256]
mask matrices --------------------
[[False False False False False False]
 [False False  True False False False]
 [False False False False False False]
 ...
 [False False False False False False]
 [False False False False False False]
 [False False False False False False]] [[False False False False False False]
 [False False False False False False]
 [False False False False False False]
 ...
 [False False False False False False]
 [False False False False False False]
 [False False False False False False]] [[False False False False False False]
 [False False False False False False]
 [False False False False False False]
 ...
 [False False  True False False False]
 [False False  True False False False]
 [False False  True False False False]]
----------------------------------
new missing matrix ------------- [[False False False False False False]
 [False False  True False False False]
 [False False False False False False]
 ...
 [False False  True False False False]
 [False False  True False False False]
 [False False  True False False False]]
metadata {'N': 1256, 'D': 6, 'cat_features': [], 'num_features': [0, 1, 2, 3, 4, 5], 'cat_target_cols': [], 'num_target_cols': [2], 'input_feature_dims': [2, 2, 2, 2, 2, 2], 'fixed_test_set_index': 256, 'auroc_setting': False}
CV Index: 0
Train-test Split 1/1
Building NPT.
All features are either categorical or numerical. Not going to bother doing feature type embeddings.
Using feature type embedding (unique embedding for categorical and numerical features).
Using feature index embedding (unique embedding for each column).
Clipping gradients to value 1.0.
Model has 31576838 parameters,batch size -1.
Initialized "lookahead_lamb" optimizer.
Warming up for 70000.0/100000.0 steps.
Initialized "flat_and_anneal" learning rate scheduler.
Initialized "cosine" augmentation/label tradeoff annealer. Annealing to minimum value in 100000 steps.
Disabled AUROC in loss module.
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
number of predicted values: ---------- tensor(193., grad_fn=<SumBackward0>)
col --------- 0
Computing PINNs Loss:
/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/Users/devu/PycharmProjects/non-parametric-transformers/npt/mask.py:108: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403207619/work/torch/csrc/utils/tensor_new.cpp:620.)
  mask = torch.sparse.FloatTensor(
Physics Loss:  tensor(0.0007, grad_fn=<MeanBackward0>)
number of predicted values: ---------- tensor(172., grad_fn=<SumBackward0>)
col --------- 1
Computing PINNs Loss:
Physics Loss:  tensor(0.0007, grad_fn=<MeanBackward0>)
number of predicted values: ---------- tensor(1., grad_fn=<SumBackward0>)
col --------- 2
Computing PINNs Loss:
Physics Loss:  tensor(0.0007, grad_fn=<MeanBackward0>)
number of predicted values: ---------- tensor(37., grad_fn=<SumBackward0>)
col --------- 2
Computing PINNs Loss:
Physics Loss:  tensor(0.0007, grad_fn=<MeanBackward0>)
number of predicted values: ---------- tensor(202., grad_fn=<SumBackward0>)
col --------- 3
Computing PINNs Loss:
Physics Loss:  tensor(0.0010, grad_fn=<MeanBackward0>)
number of predicted values: ---------- tensor(179., grad_fn=<SumBackward0>)
col --------- 4
Computing PINNs Loss:
Physics Loss:  tensor(0.0006, grad_fn=<MeanBackward0>)
number of predicted values: ---------- tensor(187., grad_fn=<SumBackward0>)
col --------- 5
Computing PINNs Loss:
Physics Loss:  tensor(0.0009, grad_fn=<MeanBackward0>)
