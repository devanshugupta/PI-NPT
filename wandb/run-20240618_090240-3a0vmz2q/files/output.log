Loaded metadata for fixed test set. n_cv_splits set to 1.
CV Splits for this dataset are cached. Loading from file.
CV Index: 0
Train-test Split 1/1
Building NPT.
All features are either categorical or numerical. Not going to bother doing feature type embeddings.
Using feature type embedding (unique embedding for categorical and numerical features).
Using feature index embedding (unique embedding for each column).
Clipping gradients to value 1.0.
Model has 31576838 parameters,batch size -1.
Initialized "lookahead_lamb" optimizer.
Warming up for 70000.0/100000.0 steps.
Initialized "flat_and_anneal" learning rate scheduler.
Initialized "cosine" augmentation/label tradeoff annealer. Annealing to minimum value in 100000 steps.
Disabled AUROC in loss module.
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[0.1057],
        [0.1959],
        [0.3352],
        ...,
        [0.5090],
        [0.2206],
        [0.0532]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [-1.4049,  0.0000],
        [ 0.1436,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/Users/devu/PycharmProjects/non-parametric-transformers/npt/mask.py:108: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403207619/work/torch/csrc/utils/tensor_new.cpp:620.)
  mask = torch.sparse.FloatTensor(
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.0011, grad_fn=<MeanBackward0>)
Done -------------------------epoch  1
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.1718],
        [-0.0837],
        [-0.1872],
        ...,
        [ 0.0498],
        [ 0.0459],
        [-0.2418]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [1.3046, 0.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.0008, grad_fn=<MeanBackward0>)
Done -------------------------epoch  2
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.1547],
        [-0.1206],
        [-0.0968],
        ...,
        [-0.0644],
        [-0.0900],
        [-0.1375]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [-0.0627,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.0009, grad_fn=<MeanBackward0>)
Done -------------------------epoch  3
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[0.2788],
        [0.1242],
        [0.3787],
        ...,
        [0.0998],
        [0.3138],
        [0.0966]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [-0.6593,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [-1.3499,  0.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.0017, grad_fn=<MeanBackward0>)
Done -------------------------epoch  4
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[0.1823],
        [0.4128],
        [0.0348],
        ...,
        [0.1186],
        [0.2547],
        [0.3175]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.0028, grad_fn=<MeanBackward0>)
Done -------------------------epoch  5
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  5
Validation loss has improved 1 times since last caching the model. Caching now.
Storing new best performing model.
Model checkpointing attempts: 0.
Stored epoch 5 model checkpoint to data/ode/ssl__True/np_seed=42__n_cv_splits=5__exp_num_runs=1/model_checkpoints/model_5.pt.
Val loss: 0.6170030832290649.
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  5
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  5
tradeoff 0.4999999980260791 | step 5 | epoch 5 | lr 0.001 | checkpoint_time 124.246 |
Train Stats
train_total_loss 0.604 | train_augmentation_total_loss 0.415 | train_augmentation_total_loss_unstd 0.648 | train_augmentation_num_loss 0.415 | train_augmentation_num_mse_loss 0.415 | train_augmentation_num_mse_loss_unstd 0.648 | train_augmentation_num_loss_unstd 0.648 | train_label_total_loss 0.794 | train_label_total_loss_unstd 0.403 | train_label_num_loss 0.794 | train_label_num_mse_loss 0.794 | train_label_num_mse_loss_unstd 0.403 | train_label_num_loss_unstd 0.403 |
Val Stats
val_total_loss 0.309 | val_label_total_loss 0.617 | val_label_total_loss_unstd 0.313 | val_label_num_loss 0.617 | val_label_num_mse_loss 0.617 | val_label_num_mse_loss_unstd 0.313 | val_label_num_loss_unstd 0.313 |
Test Stats
test_total_loss 0.017 | test_label_total_loss 0.035 | test_label_total_loss_unstd 0.018 | test_label_num_loss 0.035 | test_label_num_mse_loss 0.035 | test_label_num_mse_loss_unstd 0.018 | test_label_num_loss_unstd 0.018 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 9.5442e-05],
        [ 2.0311e-01],
        [-1.8231e-01],
        ...,
        [ 2.2350e-02],
        [ 4.8566e-02],
        [-4.0214e-01]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        ...,
        [0.0000, 1.0000],
        [1.3046, 0.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.0046, grad_fn=<MeanBackward0>)
Done -------------------------epoch  6
/Users/devu/PycharmProjects/non-parametric-transformers/npt/utils/optim_utils.py:53: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403207619/work/torch/csrc/utils/python_arg_parser.cpp:1630.)
  slow.add_(group['lookahead_alpha'], fast_p.data - slow)
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.3414],
        [-0.5332],
        [-0.4447],
        ...,
        [ 0.2932],
        [ 0.1872],
        [-0.4283]], grad_fn=<AddmmBackward0>)
tensor([[-0.2342,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.0103, grad_fn=<MeanBackward0>)
Done -------------------------epoch  7
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.3591],
        [-0.2747],
        [ 0.1819],
        ...,
        [ 0.0482],
        [ 0.4267],
        [-0.0640]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.0254, grad_fn=<MeanBackward0>)
Done -------------------------epoch  8
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.3095],
        [-0.3769],
        [ 0.4830],
        ...,
        [ 0.0066],
        [ 0.3492],
        [ 0.3370]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        ...,
        [0.0000, 1.0000],
        [1.1577, 0.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.0490, grad_fn=<MeanBackward0>)
Done -------------------------epoch  9
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.3108],
        [-0.8107],
        [ 0.4157],
        ...,
        [ 0.2971],
        [-0.6973],
        [-0.3952]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.0780, grad_fn=<MeanBackward0>)
Done -------------------------epoch  10
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  10
Validation loss has improved 1 times since last caching the model. Caching now.
Storing new best performing model.
Model checkpointing attempts: 0.
Stored epoch 10 model checkpoint to data/ode/ssl__True/np_seed=42__n_cv_splits=5__exp_num_runs=1/model_checkpoints/model_10.pt.
Val loss: 0.35355550050735474.
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  10
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  10
tradeoff 0.4999999900070256 | step 10 | epoch 10 | lr 0.001 | checkpoint_time 121.262 |
Train Stats
train_total_loss 0.429 | train_augmentation_total_loss 0.406 | train_augmentation_total_loss_unstd 0.591 | train_augmentation_num_loss 0.406 | train_augmentation_num_mse_loss 0.406 | train_augmentation_num_mse_loss_unstd 0.591 | train_augmentation_num_loss_unstd 0.591 | train_label_total_loss 0.451 | train_label_total_loss_unstd 0.229 | train_label_num_loss 0.451 | train_label_num_mse_loss 0.451 | train_label_num_mse_loss_unstd 0.229 | train_label_num_loss_unstd 0.229 |
Val Stats
val_total_loss 0.177 | val_label_total_loss 0.354 | val_label_total_loss_unstd 0.179 | val_label_num_loss 0.354 | val_label_num_mse_loss 0.354 | val_label_num_mse_loss_unstd 0.179 | val_label_num_loss_unstd 0.179 |
Test Stats
test_total_loss 0.480 | test_label_total_loss 0.959 | test_label_total_loss_unstd 0.487 | test_label_num_loss 0.959 | test_label_num_mse_loss 0.959 | test_label_num_mse_loss_unstd 0.487 | test_label_num_loss_unstd 0.487 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.8437],
        [ 0.2565],
        [-0.5587],
        ...,
        [ 1.0297],
        [-0.3989],
        [ 0.2473]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.1440, grad_fn=<MeanBackward0>)
Done -------------------------epoch  11
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.3830],
        [ 1.1827],
        [ 1.3369],
        ...,
        [ 0.4567],
        [ 1.0162],
        [ 0.9661]], grad_fn=<AddmmBackward0>)
tensor([[-0.4357,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2131, grad_fn=<MeanBackward0>)
Done -------------------------epoch  12
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.2692],
        [-0.5847],
        [-0.5066],
        ...,
        [ 1.2045],
        [ 0.1258],
        [-0.2596]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [-1.4302,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 1.2814,  0.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.0885, grad_fn=<MeanBackward0>)
Done -------------------------epoch  13
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.6527],
        [-0.1228],
        [-0.3124],
        ...,
        [ 1.0214],
        [-0.6038],
        [-0.2463]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.1591, grad_fn=<MeanBackward0>)
Done -------------------------epoch  14
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.5052],
        [-0.1773],
        [-0.0522],
        ...,
        [-0.7908],
        [-1.0717],
        [-0.5015]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2096, grad_fn=<MeanBackward0>)
Done -------------------------epoch  15
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  15
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  15
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  15
tradeoff 0.49999997581946964 | step 15 | epoch 15 | lr 0.001 | checkpoint_time 121.896 |
Train Stats
train_total_loss 0.450 | train_augmentation_total_loss 0.424 | train_augmentation_total_loss_unstd 0.754 | train_augmentation_num_loss 0.424 | train_augmentation_num_mse_loss 0.424 | train_augmentation_num_mse_loss_unstd 0.754 | train_augmentation_num_loss_unstd 0.754 | train_label_total_loss 0.476 | train_label_total_loss_unstd 0.241 | train_label_num_loss 0.476 | train_label_num_mse_loss 0.476 | train_label_num_mse_loss_unstd 0.241 | train_label_num_loss_unstd 0.241 |
Val Stats
val_total_loss 0.185 | val_label_total_loss 0.370 | val_label_total_loss_unstd 0.188 | val_label_num_loss 0.370 | val_label_num_mse_loss 0.370 | val_label_num_mse_loss_unstd 0.188 | val_label_num_loss_unstd 0.188 |
Test Stats
test_total_loss 0.747 | test_label_total_loss 1.494 | test_label_total_loss_unstd 0.758 | test_label_num_loss 1.494 | test_label_num_mse_loss 1.494 | test_label_num_mse_loss_unstd 0.758 | test_label_num_loss_unstd 0.758 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.]], requires_grad=True)
tensor([[ 1.0195],
        [ 1.0331],
        [ 0.9533],
        ...,
        [ 0.0122],
        [-1.0923],
        [ 0.7118]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [1.3649, 0.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.9884, 0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2940, grad_fn=<MeanBackward0>)
Done -------------------------epoch  16
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 1.2422],
        [-0.3372],
        [-1.3239],
        ...,
        [-0.0607],
        [ 1.0974],
        [ 1.0216]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [-1.1557,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3457, grad_fn=<MeanBackward0>)
Done -------------------------epoch  17
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.5343],
        [-0.8987],
        [ 1.4879],
        ...,
        [-0.9409],
        [ 0.1643],
        [-0.1182]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        ...,
        [0.0000, 1.0000],
        [1.1194, 0.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3168, grad_fn=<MeanBackward0>)
Done -------------------------epoch  18
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.4637],
        [-0.2370],
        [ 1.1920],
        ...,
        [ 0.1590],
        [-0.9301],
        [ 0.9649]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2093, grad_fn=<MeanBackward0>)
Done -------------------------epoch  19
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.4526],
        [ 0.7739],
        [ 0.8332],
        ...,
        [ 0.3056],
        [-0.0434],
        [ 0.9235]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [1.3548, 0.0000],
        ...,
        [0.0750, 0.0000],
        [0.8623, 0.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.1820, grad_fn=<MeanBackward0>)
Done -------------------------epoch  20
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  20
Validation loss has improved 1 times since last caching the model. Caching now.
Storing new best performing model.
Model checkpointing attempts: 0.
Stored epoch 20 model checkpoint to data/ode/ssl__True/np_seed=42__n_cv_splits=5__exp_num_runs=1/model_checkpoints/model_20.pt.
Val loss: 0.17444202303886414.
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  20
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  20
tradeoff 0.49999995546341147 | step 20 | epoch 20 | lr 0.001 | checkpoint_time 125.961 |
Train Stats
train_total_loss 0.343 | train_augmentation_total_loss 0.391 | train_augmentation_total_loss_unstd 0.619 | train_augmentation_num_loss 0.391 | train_augmentation_num_mse_loss 0.391 | train_augmentation_num_mse_loss_unstd 0.619 | train_augmentation_num_loss_unstd 0.619 | train_label_total_loss 0.295 | train_label_total_loss_unstd 0.150 | train_label_num_loss 0.295 | train_label_num_mse_loss 0.295 | train_label_num_mse_loss_unstd 0.150 | train_label_num_loss_unstd 0.150 |
Val Stats
val_total_loss 0.087 | val_label_total_loss 0.174 | val_label_total_loss_unstd 0.089 | val_label_num_loss 0.174 | val_label_num_mse_loss 0.174 | val_label_num_mse_loss_unstd 0.089 | val_label_num_loss_unstd 0.089 |
Test Stats
test_total_loss 0.429 | test_label_total_loss 0.857 | test_label_total_loss_unstd 0.435 | test_label_num_loss 0.857 | test_label_num_mse_loss 0.857 | test_label_num_mse_loss_unstd 0.435 | test_label_num_loss_unstd 0.435 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.8855],
        [ 0.8631],
        [ 0.3786],
        ...,
        [ 1.0607],
        [ 0.0929],
        [ 1.1356]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.1881, grad_fn=<MeanBackward0>)
Done -------------------------epoch  21
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.4802],
        [-0.3382],
        [-0.7501],
        ...,
        [-0.2337],
        [ 0.4121],
        [-0.1561]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.1985, grad_fn=<MeanBackward0>)
Done -------------------------epoch  22
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.8417],
        [ 0.5455],
        [ 0.2714],
        ...,
        [-0.8883],
        [-0.2115],
        [-0.9747]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3259, grad_fn=<MeanBackward0>)
Done -------------------------epoch  23
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.7364],
        [ 0.9243],
        [ 0.6633],
        ...,
        [ 1.0351],
        [-0.7965],
        [-0.9264]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 1.3414,  0.0000],
        [-0.0971,  0.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2975, grad_fn=<MeanBackward0>)
Done -------------------------epoch  24
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.3686],
        [ 1.1806],
        [ 0.6080],
        ...,
        [-0.9281],
        [-0.8785],
        [ 0.7835]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3423, grad_fn=<MeanBackward0>)
Done -------------------------epoch  25
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  25
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  25
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  25
tradeoff 0.4999999289388517 | step 25 | epoch 25 | lr 0.001 | checkpoint_time 113.278 |
Train Stats
train_total_loss 0.430 | train_augmentation_total_loss 0.391 | train_augmentation_total_loss_unstd 0.664 | train_augmentation_num_loss 0.391 | train_augmentation_num_mse_loss 0.391 | train_augmentation_num_mse_loss_unstd 0.664 | train_augmentation_num_loss_unstd 0.664 | train_label_total_loss 0.469 | train_label_total_loss_unstd 0.238 | train_label_num_loss 0.469 | train_label_num_mse_loss 0.469 | train_label_num_mse_loss_unstd 0.238 | train_label_num_loss_unstd 0.238 |
Val Stats
val_total_loss 0.128 | val_label_total_loss 0.257 | val_label_total_loss_unstd 0.130 | val_label_num_loss 0.257 | val_label_num_mse_loss 0.257 | val_label_num_mse_loss_unstd 0.130 | val_label_num_loss_unstd 0.130 |
Test Stats
test_total_loss 0.540 | test_label_total_loss 1.081 | test_label_total_loss_unstd 0.548 | test_label_num_loss 1.081 | test_label_num_mse_loss 1.081 | test_label_num_mse_loss_unstd 0.548 | test_label_num_loss_unstd 0.548 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.9287],
        [-0.8737],
        [ 0.9730],
        ...,
        [-0.3392],
        [ 0.5047],
        [ 1.1117]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3417, grad_fn=<MeanBackward0>)
Done -------------------------epoch  26
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.1687],
        [ 0.2725],
        [-1.1261],
        ...,
        [-0.4475],
        [ 0.8653],
        [ 0.9475]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.3793, 0.0000],
        [0.0000, 1.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3727, grad_fn=<MeanBackward0>)
Done -------------------------epoch  27
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.8769],
        [-0.8692],
        [ 0.8228],
        ...,
        [-0.6595],
        [ 0.8992],
        [-0.9688]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [-0.6899,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [-0.9187,  0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3120, grad_fn=<MeanBackward0>)
Done -------------------------epoch  28
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.]], requires_grad=True)
tensor([[-1.0709],
        [ 0.8800],
        [ 0.8266],
        ...,
        [-1.1763],
        [-0.8130],
        [-0.5473]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        ...,
        [-1.3379,  0.0000],
        [ 0.0000,  1.0000],
        [-1.2496,  0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3130, grad_fn=<MeanBackward0>)
Done -------------------------epoch  29
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.]], requires_grad=True)
tensor([[-0.6797],
        [ 0.6430],
        [ 0.6319],
        ...,
        [ 0.7929],
        [ 0.2905],
        [-1.0297]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [ 1.3717,  0.0000],
        [ 1.1577,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [-1.4281,  0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2430, grad_fn=<MeanBackward0>)
Done -------------------------epoch  30
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  30
Validation loss has improved 1 times since last caching the model. Caching now.
Storing new best performing model.
Model checkpointing attempts: 0.
Stored epoch 30 model checkpoint to data/ode/ssl__True/np_seed=42__n_cv_splits=5__exp_num_runs=1/model_checkpoints/model_30.pt.
Val loss: 0.16141203045845032.
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  30
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  30
tradeoff 0.4999998962457909 | step 30 | epoch 30 | lr 0.001 | checkpoint_time 512.926 |
Train Stats
train_total_loss 0.345 | train_augmentation_total_loss 0.395 | train_augmentation_total_loss_unstd 0.656 | train_augmentation_num_loss 0.395 | train_augmentation_num_mse_loss 0.395 | train_augmentation_num_mse_loss_unstd 0.656 | train_augmentation_num_loss_unstd 0.656 | train_label_total_loss 0.296 | train_label_total_loss_unstd 0.150 | train_label_num_loss 0.296 | train_label_num_mse_loss 0.296 | train_label_num_mse_loss_unstd 0.150 | train_label_num_loss_unstd 0.150 |
Val Stats
val_total_loss 0.081 | val_label_total_loss 0.161 | val_label_total_loss_unstd 0.082 | val_label_num_loss 0.161 | val_label_num_mse_loss 0.161 | val_label_num_mse_loss_unstd 0.082 | val_label_num_loss_unstd 0.082 |
Test Stats
test_total_loss 0.482 | test_label_total_loss 0.965 | test_label_total_loss_unstd 0.490 | test_label_num_loss 0.965 | test_label_num_mse_loss 0.965 | test_label_num_mse_loss_unstd 0.490 | test_label_num_loss_unstd 0.490 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.8514],
        [-0.7083],
        [ 0.2158],
        ...,
        [-0.2609],
        [ 0.4829],
        [ 0.5106]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3308, grad_fn=<MeanBackward0>)
Done -------------------------epoch  31
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.9850],
        [ 1.1043],
        [-0.9638],
        ...,
        [ 0.2198],
        [-0.9162],
        [-0.0915]], grad_fn=<AddmmBackward0>)
tensor([[-0.4685,  0.0000],
        [ 0.0000,  1.0000],
        [-1.2496,  0.0000],
        ...,
        [-1.0911,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3484, grad_fn=<MeanBackward0>)
Done -------------------------epoch  32
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 1.0346],
        [ 0.5698],
        [ 0.2181],
        ...,
        [-0.6570],
        [ 0.1744],
        [ 0.8246]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3228, grad_fn=<MeanBackward0>)
Done -------------------------epoch  33
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-1.0086],
        [-0.9259],
        [ 0.7294],
        ...,
        [-0.8985],
        [-1.0880],
        [-1.0157]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [-1.4252,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [-1.1759,  0.0000],
        [-0.7201,  0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3427, grad_fn=<MeanBackward0>)
Done -------------------------epoch  34
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.9595],
        [-0.5371],
        [-0.8873],
        ...,
        [ 0.7848],
        [-0.6958],
        [-0.8013]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3463, grad_fn=<MeanBackward0>)
Done -------------------------epoch  35
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  35
Validation loss has improved 1 times since last caching the model. Caching now.
Storing new best performing model.
Model checkpointing attempts: 0.
Stored epoch 35 model checkpoint to data/ode/ssl__True/np_seed=42__n_cv_splits=5__exp_num_runs=1/model_checkpoints/model_35.pt.
Val loss: 0.14169104397296906.
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  35
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  35
tradeoff 0.49999985738423 | step 35 | epoch 35 | lr 0.001 | checkpoint_time 128.339 |
Train Stats
train_total_loss 0.358 | train_augmentation_total_loss 0.414 | train_augmentation_total_loss_unstd 0.676 | train_augmentation_num_loss 0.414 | train_augmentation_num_mse_loss 0.414 | train_augmentation_num_mse_loss_unstd 0.676 | train_augmentation_num_loss_unstd 0.676 | train_label_total_loss 0.301 | train_label_total_loss_unstd 0.153 | train_label_num_loss 0.301 | train_label_num_mse_loss 0.301 | train_label_num_mse_loss_unstd 0.153 | train_label_num_loss_unstd 0.153 |
Val Stats
val_total_loss 0.071 | val_label_total_loss 0.142 | val_label_total_loss_unstd 0.072 | val_label_num_loss 0.142 | val_label_num_mse_loss 0.142 | val_label_num_mse_loss_unstd 0.072 | val_label_num_loss_unstd 0.072 |
Test Stats
test_total_loss 0.463 | test_label_total_loss 0.926 | test_label_total_loss_unstd 0.470 | test_label_num_loss 0.926 | test_label_num_mse_loss 0.926 | test_label_num_mse_loss_unstd 0.470 | test_label_num_loss_unstd 0.470 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-1.0602],
        [ 0.8029],
        [ 1.0296],
        ...,
        [-0.9580],
        [ 0.9285],
        [ 1.1437]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3282, grad_fn=<MeanBackward0>)
Done -------------------------epoch  36
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.]], requires_grad=True)
tensor([[ 1.0692],
        [-1.1447],
        [-1.0506],
        ...,
        [ 0.9463],
        [-0.8428],
        [ 0.9654]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.9397, 0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3754, grad_fn=<MeanBackward0>)
Done -------------------------epoch  37
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.9561],
        [-0.1619],
        [ 1.0199],
        ...,
        [-0.8653],
        [-0.6701],
        [ 1.1527]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.4002, grad_fn=<MeanBackward0>)
Done -------------------------epoch  38
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.5344],
        [ 0.8205],
        [-0.8430],
        ...,
        [ 1.0202],
        [-0.7351],
        [ 0.6059]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.4637, grad_fn=<MeanBackward0>)
Done -------------------------epoch  39
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.6804],
        [-1.1853],
        [-0.9870],
        ...,
        [-1.0058],
        [ 0.7964],
        [-1.0820]], grad_fn=<AddmmBackward0>)
tensor([[0.9145, 0.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.4627, grad_fn=<MeanBackward0>)
Done -------------------------epoch  40
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  40
Validation loss has improved 1 times since last caching the model. Caching now.
Storing new best performing model.
Model checkpointing attempts: 0.
Stored epoch 40 model checkpoint to data/ode/ssl__True/np_seed=42__n_cv_splits=5__exp_num_runs=1/model_checkpoints/model_40.pt.
Val loss: 0.11311885714530945.
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  40
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  40
tradeoff 0.4999998123541698 | step 40 | epoch 40 | lr 0.001 | checkpoint_time 129.012 |
Train Stats
train_total_loss 0.327 | train_augmentation_total_loss 0.394 | train_augmentation_total_loss_unstd 0.661 | train_augmentation_num_loss 0.394 | train_augmentation_num_mse_loss 0.394 | train_augmentation_num_mse_loss_unstd 0.661 | train_augmentation_num_loss_unstd 0.661 | train_label_total_loss 0.260 | train_label_total_loss_unstd 0.132 | train_label_num_loss 0.260 | train_label_num_mse_loss 0.260 | train_label_num_mse_loss_unstd 0.132 | train_label_num_loss_unstd 0.132 |
Val Stats
val_total_loss 0.057 | val_label_total_loss 0.113 | val_label_total_loss_unstd 0.057 | val_label_num_loss 0.113 | val_label_num_mse_loss 0.113 | val_label_num_mse_loss_unstd 0.057 | val_label_num_loss_unstd 0.057 |
Test Stats
test_total_loss 0.451 | test_label_total_loss 0.902 | test_label_total_loss_unstd 0.458 | test_label_num_loss 0.902 | test_label_num_mse_loss 0.902 | test_label_num_mse_loss_unstd 0.458 | test_label_num_loss_unstd 0.458 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.3290],
        [-1.1390],
        [-1.3309],
        ...,
        [-0.7610],
        [ 0.5531],
        [-0.8312]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [-0.8918,  0.0000],
        [-1.4167,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.4162, grad_fn=<MeanBackward0>)
Done -------------------------epoch  41
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.6287],
        [ 0.5859],
        [ 0.7279],
        ...,
        [-0.9451],
        [ 0.1980],
        [-0.8228]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.5406, 0.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2801, grad_fn=<MeanBackward0>)
Done -------------------------epoch  42
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.8724],
        [-0.9487],
        [-1.2446],
        ...,
        [ 0.9840],
        [-0.1426],
        [ 1.0277]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3915, grad_fn=<MeanBackward0>)
Done -------------------------epoch  43
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.]], requires_grad=True)
tensor([[-1.0902],
        [ 0.6423],
        [ 0.4052],
        ...,
        [-0.8778],
        [ 1.0142],
        [-1.0074]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        ...,
        [-1.4315,  0.0000],
        [ 0.0000,  1.0000],
        [-1.1557,  0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3077, grad_fn=<MeanBackward0>)
Done -------------------------epoch  44
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.4500],
        [-1.0624],
        [ 0.5575],
        ...,
        [ 0.9576],
        [ 0.6251],
        [ 0.2408]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.4121, 0.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2260, grad_fn=<MeanBackward0>)
Done -------------------------epoch  45
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  45
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  45
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  45
tradeoff 0.4999997611556115 | step 45 | epoch 45 | lr 0.001 | checkpoint_time 133.364 |
Train Stats
train_total_loss 0.356 | train_augmentation_total_loss 0.406 | train_augmentation_total_loss_unstd 0.705 | train_augmentation_num_loss 0.406 | train_augmentation_num_mse_loss 0.406 | train_augmentation_num_mse_loss_unstd 0.705 | train_augmentation_num_loss_unstd 0.705 | train_label_total_loss 0.305 | train_label_total_loss_unstd 0.155 | train_label_num_loss 0.305 | train_label_num_mse_loss 0.305 | train_label_num_mse_loss_unstd 0.155 | train_label_num_loss_unstd 0.155 |
Val Stats
val_total_loss 0.077 | val_label_total_loss 0.155 | val_label_total_loss_unstd 0.078 | val_label_num_loss 0.155 | val_label_num_mse_loss 0.155 | val_label_num_mse_loss_unstd 0.078 | val_label_num_loss_unstd 0.078 |
Test Stats
test_total_loss 0.455 | test_label_total_loss 0.909 | test_label_total_loss_unstd 0.461 | test_label_num_loss 0.909 | test_label_num_mse_loss 0.909 | test_label_num_mse_loss_unstd 0.461 | test_label_num_loss_unstd 0.461 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.]], requires_grad=True)
tensor([[-0.8276],
        [ 0.9417],
        [-1.0494],
        ...,
        [-0.7435],
        [ 0.7845],
        [-1.0779]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [-1.4252,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [-0.8365,  0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.1746, grad_fn=<MeanBackward0>)
Done -------------------------epoch  46
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.9255],
        [-1.1092],
        [ 0.7225],
        ...,
        [ 0.3303],
        [-0.9723],
        [-0.0633]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.1793, grad_fn=<MeanBackward0>)
Done -------------------------epoch  47
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.]], requires_grad=True)
tensor([[-1.2167],
        [-0.2135],
        [ 0.7641],
        ...,
        [ 0.7170],
        [ 0.9036],
        [ 0.5211]], grad_fn=<AddmmBackward0>)
tensor([[-1.3899,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 1.1931,  0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2227, grad_fn=<MeanBackward0>)
Done -------------------------epoch  48
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-1.0053],
        [-1.1747],
        [ 0.9099],
        ...,
        [ 0.4657],
        [ 0.8882],
        [ 1.0170]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3829, grad_fn=<MeanBackward0>)
Done -------------------------epoch  49
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.8197],
        [-0.1795],
        [ 0.9156],
        ...,
        [ 1.1640],
        [-1.1129],
        [-0.8832]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [-0.1315,  0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.4931, grad_fn=<MeanBackward0>)
Done -------------------------epoch  50
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  50
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  50
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  50
tradeoff 0.4999997037885564 | step 50 | epoch 50 | lr 0.001 | checkpoint_time 133.333 |
Train Stats
train_total_loss 0.368 | train_augmentation_total_loss 0.406 | train_augmentation_total_loss_unstd 0.718 | train_augmentation_num_loss 0.406 | train_augmentation_num_mse_loss 0.406 | train_augmentation_num_mse_loss_unstd 0.718 | train_augmentation_num_loss_unstd 0.718 | train_label_total_loss 0.330 | train_label_total_loss_unstd 0.167 | train_label_num_loss 0.330 | train_label_num_mse_loss 0.330 | train_label_num_mse_loss_unstd 0.167 | train_label_num_loss_unstd 0.167 |
Val Stats
val_total_loss 0.073 | val_label_total_loss 0.147 | val_label_total_loss_unstd 0.074 | val_label_num_loss 0.147 | val_label_num_mse_loss 0.147 | val_label_num_mse_loss_unstd 0.074 | val_label_num_loss_unstd 0.074 |
Test Stats
test_total_loss 0.454 | test_label_total_loss 0.908 | test_label_total_loss_unstd 0.461 | test_label_num_loss 0.908 | test_label_num_mse_loss 0.908 | test_label_num_mse_loss_unstd 0.461 | test_label_num_loss_unstd 0.461 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.9509],
        [ 0.8307],
        [ 0.0528],
        ...,
        [ 0.8471],
        [ 0.8960],
        [-0.1050]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        ...,
        [1.3751, 0.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.5210, grad_fn=<MeanBackward0>)
Done -------------------------epoch  51
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.]], requires_grad=True)
tensor([[-0.9074],
        [ 0.8824],
        [-0.8410],
        ...,
        [ 0.3477],
        [ 0.9910],
        [-1.0325]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [ 1.0119,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [-0.3021,  0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.4211, grad_fn=<MeanBackward0>)
Done -------------------------epoch  52
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.9599],
        [-0.7985],
        [-0.3485],
        ...,
        [-1.1809],
        [-0.7468],
        [ 1.0256]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [-0.8081,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2720, grad_fn=<MeanBackward0>)
Done -------------------------epoch  53
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.7129],
        [ 0.0910],
        [ 0.7366],
        ...,
        [-0.9105],
        [ 0.9685],
        [ 0.4827]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [-0.2000,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.1856, grad_fn=<MeanBackward0>)
Done -------------------------epoch  54
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.0752],
        [ 0.9805],
        [-0.0537],
        ...,
        [-0.6656],
        [ 0.8710],
        [ 0.5740]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.6934, 0.0000],
        [0.0000, 1.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3109, grad_fn=<MeanBackward0>)
Done -------------------------epoch  55
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  55
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  55
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  55
tradeoff 0.49999964025300586 | step 55 | epoch 55 | lr 0.001 | checkpoint_time 133.853 |
Train Stats
train_total_loss 0.363 | train_augmentation_total_loss 0.410 | train_augmentation_total_loss_unstd 0.761 | train_augmentation_num_loss 0.410 | train_augmentation_num_mse_loss 0.410 | train_augmentation_num_mse_loss_unstd 0.761 | train_augmentation_num_loss_unstd 0.761 | train_label_total_loss 0.315 | train_label_total_loss_unstd 0.160 | train_label_num_loss 0.315 | train_label_num_mse_loss 0.315 | train_label_num_mse_loss_unstd 0.160 | train_label_num_loss_unstd 0.160 |
Val Stats
val_total_loss 0.081 | val_label_total_loss 0.163 | val_label_total_loss_unstd 0.083 | val_label_num_loss 0.163 | val_label_num_mse_loss 0.163 | val_label_num_mse_loss_unstd 0.083 | val_label_num_loss_unstd 0.083 |
Test Stats
test_total_loss 0.537 | test_label_total_loss 1.075 | test_label_total_loss_unstd 0.545 | test_label_num_loss 1.075 | test_label_num_mse_loss 1.075 | test_label_num_mse_loss_unstd 0.545 | test_label_num_loss_unstd 0.545 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.0985],
        [ 0.9943],
        [ 1.0135],
        ...,
        [-0.3991],
        [ 1.1782],
        [-0.1054]], grad_fn=<AddmmBackward0>)
tensor([[0.0750, 0.0000],
        [1.0993, 0.0000],
        [0.5406, 0.0000],
        ...,
        [0.8354, 0.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2745, grad_fn=<MeanBackward0>)
Done -------------------------epoch  56
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 1.1039],
        [ 0.1466],
        [ 1.1618],
        ...,
        [-0.3904],
        [-1.2018],
        [ 0.8986]], grad_fn=<AddmmBackward0>)
tensor([[0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        ...,
        [0.0000, 1.0000],
        [0.0000, 1.0000],
        [0.7516, 0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3102, grad_fn=<MeanBackward0>)
Done -------------------------epoch  57
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.9127],
        [ 0.5910],
        [ 1.2973],
        ...,
        [ 0.7778],
        [-1.0981],
        [-1.0001]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3798, grad_fn=<MeanBackward0>)
Done -------------------------epoch  58
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.1055],
        [ 0.9362],
        [-0.2932],
        ...,
        [-0.1627],
        [ 0.7778],
        [-0.6518]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.4516, grad_fn=<MeanBackward0>)
Done -------------------------epoch  59
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.7027],
        [-0.1328],
        [-0.5193],
        ...,
        [ 0.6980],
        [-0.5253],
        [ 1.0602]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.4579, grad_fn=<MeanBackward0>)
Done -------------------------epoch  60
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  60
Validation loss has improved 1 times since last caching the model. Caching now.
Storing new best performing model.
Model checkpointing attempts: 0.
Stored epoch 60 model checkpoint to data/ode/ssl__True/np_seed=42__n_cv_splits=5__exp_num_runs=1/model_checkpoints/model_60.pt.
Val loss: 0.08651959896087646.
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  60
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  60
tradeoff 0.49999957054896144 | step 60 | epoch 60 | lr 0.001 | checkpoint_time 147.980 |
Train Stats
train_total_loss 0.316 | train_augmentation_total_loss 0.395 | train_augmentation_total_loss_unstd 0.715 | train_augmentation_num_loss 0.395 | train_augmentation_num_mse_loss 0.395 | train_augmentation_num_mse_loss_unstd 0.715 | train_augmentation_num_loss_unstd 0.715 | train_label_total_loss 0.238 | train_label_total_loss_unstd 0.121 | train_label_num_loss 0.238 | train_label_num_mse_loss 0.238 | train_label_num_mse_loss_unstd 0.121 | train_label_num_loss_unstd 0.121 |
Val Stats
val_total_loss 0.043 | val_label_total_loss 0.087 | val_label_total_loss_unstd 0.044 | val_label_num_loss 0.087 | val_label_num_mse_loss 0.087 | val_label_num_mse_loss_unstd 0.044 | val_label_num_loss_unstd 0.044 |
Test Stats
test_total_loss 0.474 | test_label_total_loss 0.948 | test_label_total_loss_unstd 0.481 | test_label_num_loss 0.948 | test_label_num_mse_loss 0.948 | test_label_num_mse_loss_unstd 0.481 | test_label_num_loss_unstd 0.481 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.7943],
        [-1.1491],
        [-0.1496],
        ...,
        [ 0.9386],
        [-1.0134],
        [-1.0990]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [-1.2496,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [-1.1759,  0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3926, grad_fn=<MeanBackward0>)
Done -------------------------epoch  61
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.4573],
        [ 0.9735],
        [ 0.9509],
        ...,
        [-1.0105],
        [ 1.0095],
        [ 0.2563]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 1.3150,  0.0000],
        ...,
        [-1.3978,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3845, grad_fn=<MeanBackward0>)
Done -------------------------epoch  62
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.4727],
        [-0.9148],
        [ 0.0122],
        ...,
        [-1.0574],
        [-1.0546],
        [ 0.5209]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.4024, grad_fn=<MeanBackward0>)
Done -------------------------epoch  63
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.2447],
        [ 1.0210],
        [ 0.7291],
        ...,
        [ 0.2237],
        [ 0.9715],
        [ 0.6733]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3216, grad_fn=<MeanBackward0>)
Done -------------------------epoch  64
end_experiment or self.eval_check(epoch) False True
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.8687],
        [-0.5490],
        [-0.5466],
        ...,
        [ 0.8688],
        [ 0.8389],
        [-0.6485]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        ...,
        [ 0.8080,  0.0000],
        [ 0.0000,  1.0000],
        [-0.3693,  0.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2693, grad_fn=<MeanBackward0>)
Done -------------------------epoch  65
Dataset mode -----  val
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  65
Validation loss has improved 1 times since last caching the model. Caching now.
Storing new best performing model.
Model checkpointing attempts: 0.
Stored epoch 65 model checkpoint to data/ode/ssl__True/np_seed=42__n_cv_splits=5__exp_num_runs=1/model_checkpoints/model_65.pt.
Val loss: 0.06094059348106384.
Dataset mode -----  train
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  65
Dataset mode -----  test
Using torch no grad, eval model= True
Physics Loss:  0
Done -------------------------epoch  65
tradeoff 0.4999994946764249 | step 65 | epoch 65 | lr 0.001 | checkpoint_time 144.599 |
Train Stats
train_total_loss 0.329 | train_augmentation_total_loss 0.429 | train_augmentation_total_loss_unstd 0.623 | train_augmentation_num_loss 0.429 | train_augmentation_num_mse_loss 0.429 | train_augmentation_num_mse_loss_unstd 0.623 | train_augmentation_num_loss_unstd 0.623 | train_label_total_loss 0.230 | train_label_total_loss_unstd 0.116 | train_label_num_loss 0.230 | train_label_num_mse_loss 0.230 | train_label_num_mse_loss_unstd 0.116 | train_label_num_loss_unstd 0.116 |
Val Stats
val_total_loss 0.030 | val_label_total_loss 0.061 | val_label_total_loss_unstd 0.031 | val_label_num_loss 0.061 | val_label_num_mse_loss 0.061 | val_label_num_mse_loss_unstd 0.031 | val_label_num_loss_unstd 0.031 |
Test Stats
test_total_loss 0.439 | test_label_total_loss 0.879 | test_label_total_loss_unstd 0.446 | test_label_num_loss 0.879 | test_label_num_mse_loss 0.879 | test_label_num_mse_loss_unstd 0.446 | test_label_num_loss_unstd 0.446 |
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-0.4693],
        [ 0.5619],
        [-1.0700],
        ...,
        [-0.8415],
        [-1.1425],
        [-1.1449]], grad_fn=<AddmmBackward0>)
tensor([[-1.3611,  0.0000],
        [ 1.3603,  0.0000],
        [ 0.0000,  1.0000],
        ...,
        [-0.1315,  0.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.2691, grad_fn=<MeanBackward0>)
Done -------------------------epoch  66
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[-1.1022],
        [ 1.0577],
        [ 1.0627],
        ...,
        [-0.2412],
        [ 0.9343],
        [ 1.0125]], grad_fn=<AddmmBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.3774, grad_fn=<MeanBackward0>)
Done -------------------------epoch  67
end_experiment or self.eval_check(epoch) False False
Dataset mode -----  train
Computing PINNs Loss:
mask matrix ------ tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        ...,
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], requires_grad=True)
tensor([[ 0.8674],
        [ 1.1841],
        [-1.0688],
        ...,
        [ 0.2427],
        [-0.8044],
        [ 0.9000]], grad_fn=<AddmmBackward0>)
tensor([[ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [-1.4281,  0.0000],
        ...,
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000],
        [ 0.0000,  1.0000]], requires_grad=True)
Gradients shape ------- torch.Size([1256, 2]) torch.Size([1256, 2])
Physics Loss:  tensor(0.4563, grad_fn=<MeanBackward0>)
Done -------------------------epoch  68
Traceback (most recent call last):
  File "run.py", line 204, in <module>
    main(args)
  File "run.py", line 23, in main
    run_cv(args=args, wandb_args=wandb_args)
  File "run.py", line 117, in run_cv
    run_cv_splits(wandb_args, args, c, wandb_run)
  File "run.py", line 195, in run_cv_splits
    trainer.train_and_eval()
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 216, in train_and_eval
    if self.per_epoch_train_eval(epoch=epoch):
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 171, in per_epoch_train_eval
    train_loss = self.run_epoch(dataset_mode='train', epoch=epoch,
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 437, in run_epoch
    self.run_batch(
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 563, in run_batch
    self.scaler.scale(train_loss).backward()
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/model/npt.py", line 272, in <lambda>
    lambda grad: torch.clamp(grad, -clip_value, clip_value))
KeyboardInterrupt
Traceback (most recent call last):
  File "run.py", line 204, in <module>
    main(args)
  File "run.py", line 23, in main
    run_cv(args=args, wandb_args=wandb_args)
  File "run.py", line 117, in run_cv
    run_cv_splits(wandb_args, args, c, wandb_run)
  File "run.py", line 195, in run_cv_splits
    trainer.train_and_eval()
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 216, in train_and_eval
    if self.per_epoch_train_eval(epoch=epoch):
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 171, in per_epoch_train_eval
    train_loss = self.run_epoch(dataset_mode='train', epoch=epoch,
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 437, in run_epoch
    self.run_batch(
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/train.py", line 563, in run_batch
    self.scaler.scale(train_loss).backward()
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/Users/devu/PycharmProjects/non-parametric-transformers/npt/model/npt.py", line 272, in <lambda>
    lambda grad: torch.clamp(grad, -clip_value, clip_value))
KeyboardInterrupt