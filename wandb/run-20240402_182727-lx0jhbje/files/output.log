CV Splits for this dataset are cached. Loading from file.
CV Index: 0
Train-test Split 1/5
c.exp_n_runs = 1. Stopping at 1 splits.
Building NPT.
Using feature type embedding (unique embedding for categorical and numerical features).
Using feature index embedding (unique embedding for each column).
Clipping gradients to value 1.0.
Model has 205023200 parameters,batch size -1.
Initialized "lookahead_lamb" optimizer.
Warming up for 70000.0/100000.0 steps.
Initialized "flat_and_anneal" learning rate scheduler.
/Users/devu/anaconda3/envs/npt/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/Users/devu/PycharmProjects/non-parametric-transformers/npt/mask.py:108: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403207619/work/torch/csrc/utils/tensor_new.cpp:620.)
  mask = torch.sparse.FloatTensor(
Initialized "cosine" augmentation/label tradeoff annealer. Annealing to minimum value in 100000 steps.
Using AUROC in loss module.
Validation loss has improved 1 times since last caching the model. Caching now.
Storing new best performing model.
Model checkpointing attempts: 0.
Stored epoch 5 model checkpoint to data/breast-cancer/ssl__True/np_seed=42__n_cv_splits=5__exp_num_runs=1/model_checkpoints/model_5.pt.
Val loss: 0.5946316123008728.
tradeoff 0.4999999980260791 | step 5 | epoch 5 | lr 0.001 | checkpoint_time 39.241 |
Train Stats
train_total_loss 0.740 | train_augmentation_total_loss 0.867 | train_augmentation_total_loss_unstd 15818.319 | train_augmentation_num_loss 0.867 | train_augmentation_num_mse_loss 0.867 | train_augmentation_num_mse_loss_unstd 15818.319 | train_augmentation_num_loss_unstd 15818.319 | train_label_total_loss 0.613 | train_label_total_loss_unstd 0.613 | train_label_cat_loss 0.613 | train_label_cat_accuracy 0.688 | train_label_auroc 0.978 |
Val Stats
val_total_loss 0.297 | val_label_total_loss 0.595 | val_label_total_loss_unstd 0.595 | val_label_cat_loss 0.595 | val_label_cat_accuracy 0.807 | val_label_auroc 0.996 |
Test Stats
test_total_loss 0.305 | test_label_total_loss 0.611 | test_label_total_loss_unstd 0.611 | test_label_cat_loss 0.611 | test_label_cat_accuracy 0.702 | test_label_auroc 0.995 |
/Users/devu/PycharmProjects/non-parametric-transformers/npt/utils/optim_utils.py:53: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403207619/work/torch/csrc/utils/python_arg_parser.cpp:1630.)
  slow.add_(group['lookahead_alpha'], fast_p.data - slow)
Validation loss has improved 1 times since last caching the model. Caching now.
Storing new best performing model.
Model checkpointing attempts: 0.
Stored epoch 10 model checkpoint to data/breast-cancer/ssl__True/np_seed=42__n_cv_splits=5__exp_num_runs=1/model_checkpoints/model_10.pt.
